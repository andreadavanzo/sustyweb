<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<title>Sustainable Tooling And Reporting (STAR) 1.0</title>
		<!--
			Fix for ReSpec table layout and overflow issue.
		-->
		<style>
			.flow { overflow-x: auto; }
			.flow table { border-collapse:collapse; border-spacing:0; white-space: nowrap; }
			.flow td, .flow th { border: 1px solid #000000; text-align: center; }
			.red { color: #FF0000; }
		</style>
		<script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove" defer>
		</script>
		<script class="remove">
		var respecConfig = {
			editors: [
				{
					name: "Alexander Dawson",
					url: "https://alexanderdawson.com/",
					w3cid: 49702,
				},
				{
					name: "Tim Frick",
					url: "https://www.mightybytes.com/",
					company: "Mightybytes",
					w3cid: 62394,
				}
			],
			edDraftURI: "https://w3c.github.io/sustyweb/star.html",
			github: "https://github.com/w3c/sustyweb/",
			group: "sustyweb",
			latestVersion: "https://w3c.github.io/sustyweb/star.html",
			localBiblio: {
				"WAI": {
					title: "Web Accessibility Initiative",
					href: "https://www.w3.org/WAI/",
					status: "Informational",
					publisher: "WAI",
				}
			},
			specStatus: "CG-DRAFT",
		}
		</script>
	</head>
	<body>
		<section id="abstract"> <!-- Abstract -->
			<p>Sustainable Tooling And Reporting (<abbr title="Sustainable Tooling And Reporting">STAR</abbr>) 1.0 provides information, examples, and metrics data to complement the Web Sustainability Guidelines (<abbr title="Web Sustainability Guidelines">WSG</abbr>) 1.0 specification. Within this supplementary document, you will find implementation advice (for external groups wishing to incorporate sustainability in their work), an evaluation methodology (for testing conformance), a categorized series of techniques (potential implementations and case studies), and a test suite (metrics data on impact and machine automation capability).</p>
			<p>As with the <abbr title="Web Sustainability Guidelines">WSGs</abbr>, these features have been inspired by the work of the Web Accessibility Initiative ([[WAI]]). They have also been curated with a Web sustainability methodology, with the goal of better understanding the digital landscape's role in reducing harm to the wider ecosystem (regarding people and the planet).</p>
			<p>For the normative technical specification, see <a href="https://w3c.github.io/sustyweb/">https://w3c.github.io/sustyweb/</a>.</p>
			<p>Help improve this page by sharing your ideas, suggestions, or comments via <a href="https://github.com/w3c/sustyweb/issues/">GitHub issues</a>.</p>
		</section>
		<section id="sotd" class="override"></section> <!-- Ignore -->
		<section> <!-- Implementation -->
			<h2>Implementation Advice</h2>
			<p>The following section provides advisory guidance for other specification writers and external groups wishing to incorporate digital sustainability within their work (such as W3C Working and Community Groups). We are primarily a group dedicated to fostering sustainable change in Web technologies associated with the creation of websites and applications. While it is outside of our group's scope to conduct horizontal reviews of other group's specifications, we may request or accept requests to collaborate with or assist in coordination with other groups to implement sustainable change.</p>
			<section> <!-- Considerations -->
				<h3>Considerations</h3>
				<p>The WSGs have a broad appeal, designed to impact a wide range of Web technologies and related infrastructure as appropriate. With this in mind, when first starting to look to incorporate sustainability within a body of work you may find that certain guidelines more than others will apply to practices.</p>
				<p>When designing any fledgling body of work it's worth considering the following:</p>
				<ul>
					<li>Can a sustainability policy be put in place to vet work appropriately?</li>
					<li>If any guidelines are applicable, can they be included as "hard and fast rules"?</li>
					<li>If not (due to a conflict), can this be resolved without impacting the benefit?</li>
					<li>Can research to identify any sustainability benefits that are yet undiscovered be undertaken?</li>
					<li>Is education for consumers on a work's environmental impact being provided?</li>
				</ul>
				<div class="note">
					<p>When creating specifications or industry-specific documents, cross-reference to specific WSG guidelines that are appropriate for a body of work to connect elements of content to applicable sustainability goals.</p>
					<p>Create new sustainability guidelines that are explicitly targeted for a technology (that may be too niche to be included within the WSGs). This would provide additional Success Criteria for an audience to meet.</p>
					<p>If you do wish to create additional targeted guidelines, please first consult the <abbr title="Sustainable Web Design Community Group">SWD-CG</abbr> as we may be able to include them within the main WSGs or provide guidance to avoid conflicts with other existing guidelines.</p>
				</div>
			</section>
			<section> <!-- Methodology -->
				<h3>Methodology</h3>
				<p>With the above considerations taken into account, a good next step is to consider sustainability within content and treat sustainability as any other impact target (such as accessibility or performance) by trying to drive change through metrics data. If research exists to back a particular technique as more performant, it's likely to be more sustainable. Often there will be cases where evidence does not exist as Web sustainability is an evolving field and as such, a common sense approach (considering the variables that can impact people and the planet) will be the best method if metrics data cannot be provided to identify the most sustainable option.</p>
				<p>Every body of work will have its approach to this and a progress over-perfection methodology is preferred (as doing something is ultimately better than waiting for an ideal fix), but as a general consideration for those who are creating documents that are relied upon by large numbers of individuals, the ESG model which doesn't just account for emissions and the environment but also social factors and good governance are an ideal template to work from. In the context of the Internet this accounts for everyday (but important) factors such as performance, accessibility, privacy by design, security, and reducing waste which all as a by-product have an environmental impact.</p>
				<p>It's also important to note that different bodies will have their sustainability challenges, for example, those working on native <abbr title="Application Programming Interfaces">APIs</abbr> are more likely to encounter hardware resource consumption (energy usage), whereas language standards will be more considerate of implementors, accessibility, and improving developer workflows. As such, it's worth coordinating with other groups with aligned goals and discussing their sustainability approaches to align work and help improve theirs, accounting for different variables.</p>
				<p class="note">Providing sustainability guidance within work can be presented in many ways. One option is to integrate it within existing guidance or specifications (amending the content). Another is to provide notes or in-page sections dedicated to sustainability providing coverage. Or to gently guide individuals into the subject, a dedicated supplement that will be adapted or merged into the specification at the next major version (giving individuals time to adapt) could be created.</p>
			</section>
		</section>
		<section> <!-- Evaluation Methodology -->
			<h2>Evaluation Methodology</h2>
			<p>Evaluating the extent to which a website implements the Web Sustainability Guidelines (WSG) is a process involving several steps. The activities carried out within these steps are influenced by many aspects such as the type of website (e.g. static, dynamic, responsive, mobile, application, etc.); its size, complexity, and the technologies used to create the website (e.g. <abbr title="Hypertext Markup Language">HTML</abbr>, <abbr title="Cascading Stylesheets">CSS</abbr>, <abbr title="JavaScript">JS</abbr>, <abbr title="Portable Document Format">PDF</abbr>, etc.); how much knowledge the evaluators have about the process used to design and develop the website; and the main purpose for the evaluation (e.g. to issue a sustainability statement, to plan a redesign process, to perform research, etc.).</p>
			<p>This methodology describes the steps that are common for comprehensive evaluation of the extent of websites and applications to implement WSG 1.0. It highlights considerations for evaluators to apply these steps in the context of a particular product or service. It does not replace the need for quality assurance measures that are implemented throughout the design, development, and maintenance of websites or applications to ensure their sustainability conformance. Following this methodology will help evaluators apply good practice, avoid commonly made mistakes, and achieve more comparable results. However, in the majority of situations using this methodology alone, without additional quality assurance measures, does not directly result in a sustainable product or service that meets the WSG 1.0 success criteria and guidelines.</p>
			<p><strong>This methodology does not in any way add to or change the requirements defined by the normative WSG 1.0 specification</strong>, nor does it provide instructions on feature-by-feature evaluation of web content. The methodology can be used in conjunction with techniques and examples for meeting WSG 1.0 success criteria, such as the techniques documented within this STAR supplement, but does not require this or any other specific set of techniques.</p>
			<p>This methodology is intended for people who are experienced in evaluating Web sustainability using WSG 1.0 and its supporting resources. It provides guidance on good practice in defining the evaluation scope, exploring the target website, selecting representative samples from websites where it is not feasible to evaluate all content, auditing the selected samples, reporting the evaluation findings, and if necessary - implementing sustainable change. It does not specify particular web technologies, evaluation tools, web browsers, or other software to use for evaluation. It is also suitable for use in different evaluation contexts, including self-assessment and third-party evaluation.</p>
			<section class="notoc"> <!-- Purposes for this Methodology -->
				<h3>Purposes for this Methodology</h3>
				<p>In many situations it is necessary to evaluate the sustainability of a website or application, for example before releasing, acquiring, or redesigning the product or service, and for monitoring the sustainability of a website or application over time. This methodology is designed for anyone who wants to follow a common approach for evaluating the compliance of websites to WSG 1.0. This includes:</p>
				<ul>
					<li>Web consultants who want to analyze and report the sustainability  conformance of websites or applications, to inform website owners.</li>
					<li>Web sustainability evaluation service providers who want to evaluate products and services to validate sustainability compliance.</li>
					<li>Website designers and developers who want to evaluate the sustainability compliance of their websites or applications to monitor or improve them.</li>
					<li>Website owners, procurers, and suppliers who want to learn about the sustainability compliance of their websites.</li>
					<li>Web compliance and quality assurance managers who want to ensure that they meet quality and policy requirements.</li>
					<li>Web sustainability monitoring activities are used to benchmark and compare sustainability compliance over time.</li>
					<li>Web sustainability researchers and environmental advocates or activists who want to explore sustainability compliance practices.</li>
					<li>Web sustainability trainers and educators who want to teach approaches for evaluating the sustainability of websites and applications.</li>
					<li>Webmasters, content authors, designers, developers, and others who want to learn more about web sustainability and evaluation.</li>
				</ul>
			</section>
			<section> <!-- Usage and Scope -->
				<h3>Usage and Scope</h3>
				<p class="ednote" title="Awaiting Content">
					This will contain our version of [[WCAG-EM]] Using this Methodology and Scope of Applicability.
				</p>
			</section>
			<section> <!-- Evaluation Procedure -->
				<h3>Evaluation Procedure</h3>
				<p class="ednote" title="Awaiting Content">
					This will contain our version of [[WCAG-EM]] Evaluation Procedure.
				</p>
			</section>
		</section>
		<section class="informative"> <!-- WSG Techniques -->
			<h2>WSG Techniques</h2>
			<section> <!-- Techniques Overview -->
				<h3>Techniques Overview</h3>
				<p>WSG 1.0 guidelines and success criteria are designed to be broadly applicable to current and future web technologies, including dynamic applications, mobile, digital television, etc.</p>
				<p>STAR techniques guide web content authors and evaluators on meeting WSG success criteria and guidelines, which include code examples, resources, and tests. Techniques are updated periodically to cover additional current best practices and changes in technologies and tools.</p>
				<p>The three types of techniques for STAR 1.0 are explained below:</p>
				<ul>
					<li>Sufficient techniques</li>
					<li>Advisory techniques</li>
					<li>Failures</li>
				</ul>
				<section class="notoc"> <!-- Techniques are Informative -->
					<h3>Techniques are Informative</h3>
					<p>Techniques are informative, meaning they are not required. The basis for determining conformance to WSG is the success criteria from guidelines within the specification and not the techniques themselves. We also caution against requiring specific techniques or tests mentioned within this document. The only thing that should be required is meeting the WSG success criteria.</p>
				</section>
				<section class="notoc"> <!-- Technique Types -->
					<h3>Technique Types</h3>
					<p><em>Sufficient techniques</em> are reliable ways to meet the success criteria.</p>
					<ul>
						<li>From an author or evaluator's perspective: If you use sufficient techniques for a given criterion correctly and it is sustainable within the context of its wider application and usage, you can be confident that you met the success criterion.</li>
					</ul>
					<p><em>Advisory techniques</em> are suggested ways to improve sustainability. They are often very helpful and maybe a significant way of reducing emissions or meeting primary <abbr title="Environment, Social, and Governance">ESG</abbr> objectives.</p>
					<p>Advisory techniques are not designated as sufficient techniques for various reasons such as:</p>
					<ul>
						<li>They may not be sufficient to meet the full requirements of the success criteria;</li>
						<li>They may be based on technology that is not yet stable;</li>
						<li>They may not be testable;</li>
					</ul>
					<p>Authors are encouraged to apply all of the techniques where appropriate to best address the widest range of sustainability benefits.</p>
					<p><em>Failures</em> are things that cause sustainability issues and fail specific success criteria. The documented failures are useful for:</p>
					<ul>
						<li>Authors to know what to avoid,</li>
						<li>Evaluators to use for checking if the content does not meet WSG success criteria.</li>
					</ul>
					<p>Content that has a failure does not meet WSG success criteria unless an alternate version is provided without the failure.</p>
				</section>
				<section class="notoc"> <!-- Scope and Limitations -->
					<h3>Scope and Limitations</h3>
					<p>In addition to the techniques, there are other ways to meet WSG success criteria. STAR techniques are not comprehensive and may not cover newer technologies and situations. Web content does not have to use STAR techniques to conform to WSG. Content authors can develop different techniques. For example, an author could develop a technique for an existing, or other new technology. Other organizations may develop sets of techniques to meet WSG success criteria. Any techniques can be sufficient if they satisfy the success criterion.</p>
					<p>Publication of techniques for a specific technology does not imply that the technology can be used in all situations to create content that meets WSG success criteria and conformance requirements. Developers need to be aware of the limitations of specific technologies and provide content in a way that is sustainable on multiple levels.</p>
					<p>The <a href="https://www.w3.org/community/sustyweb/">Sustainable Web Design Community Group</a> (<abbr title="Sustainable Web Design Community Group">SWD-CG</abbr>) encourages people to submit new techniques so that they can be considered for inclusion in updates of the STAR 1.0 document. Please submit techniques for consideration using <a href="https://github.com/w3c/sustyweb/issues/">GitHub issues</a>.</p>
				</section>
				<section class="notoc"> <!-- Testing Techniques -->
					<h3>Testing Techniques</h3>
					<p>Each technique has tests that help:</p>
					<ul>
						<li>Authors verify that they implemented the technique properly, and</li>
						<li>Evaluators determine if web content meets the technique.</li>
					</ul>
					<p>The tests are only for a technique, they are not tests for conformance to WSG success criteria.</p>
					<ul>
						<li>Failing a technique test does not necessarily mean failing WSG, because the techniques are discrete (that is, they address one specific point) and they are not required.</li>
						<li>Content can meet WSG success criteria in different ways other than STAR published sufficient techniques.</li>
					</ul>
					<p>While the techniques are useful for evaluating the content, evaluations must go beyond just checking the sufficient technique tests to evaluate how content conforms to WSG success criteria (considerations such as accessibility, privacy, security, etc).</p>
					<p>Failures are particularly useful for evaluations because they do indicate non-conformance (unless an alternate version is provided without the failure).</p>
				</section>
				<section class="notoc"> <!-- Using the Techniques -->
					<h3>Using the Techniques</h3>
					<p>Techniques for WSG are not intended to be used as a standalone document. Instead, it is expected that content authors will usually use our quick reference to read the WCAG success criteria and follow links from there to specific guidelines within the specification (including examples and techniques).</p>
					<p>Some techniques may describe how to provide alternate ways for visitors to get content. Alternative content, files, and formats must also conform to WSG and meet relevant success criteria, thereby becoming sustainable.</p>
					<p>The code examples in the techniques are intended to demonstrate only the specific point discussed in the technique. They might not demonstrate best practices for other aspects of sustainability, accessibility, usability, or coding not related to the technique. They are not intended to be copied and used as the basis for developing web content.</p>
					<p>Many techniques point to "working examples" that are more robust and may be appropriate for copying and integrating into web content.</p>
				</section>
			</section>
			<section> <!-- User-Experience Design -->
				<h3><dfn data-lt="UX">User-Experience Design</dfn></h3>
				<p>Each of the below can be shown or hidden by clicking on the technique you wish to display.</p>
				<ol>
					<li> <!-- UX01-1: Produce a List of Variables To Monitor for Sustainability Impacts -->
						<details>
							<summary>UX01-1: Produce a List of Variables To Monitor for Sustainability Impacts</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to create a maintainable list of different variables that may impact the sustainability of a product or service over time. By having this list in place, everyone in the creation process can closely monitor the application or website against each variable to determine if an ESG variable present on the list will require resolution either before, during, or after a product or service is launched.</p>
								<p>This list should be created during ideation if possible but can also be machine-generated from a pre-determined list of known ESG factors using evidence and research. The content of this material could be further tested through automation if such variables can be aligned with product capabilities however at a bare minimum, this list must be publicly visible (such as within a sustainability statement) and utilized in-house to enact sustainable change.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://websitesustainability.com/cache/files/variables.pdf">The Variables of Website Sustainability</a> provides a comprehensive map of the various carbon traps that exist on the Internet. From business and external elements to development and rendering, it provides a visual representation of the energy usage that can trigger emissions.</li>
									<li>The <a href="https://blog.scottlogic.com/2024/02/13/announcing-the-proposed-technology-carbon-standard.html">(Proposed) Technology Carbon Standard</a> is an approach to classify an organization's technology carbon footprint. It's based on the Greenhouse Gas Protocol (GHG) and aligns with Scope 1, 2, and 3 emissions.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Identify all machine-generated variables (hardware / software, etc).</li>
									<li>Identify all human-generated variables (business / user, etc).</li>
									<li>Create a checklist to be published within sustainability processes.</li>
									<li>Circulate among employees as part of the testing workflow.</li>
									<li>Check that all variables have been accounted for before publication.</li>
									<li>Report the findings within your accessibility statement.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX02-1: Use Quantitative Research To Measure the Needs of Visitors and Affected Communities -->
						<details>
							<summary>UX02-1: Use Quantitative Research To Measure the Needs of Visitors and Affected Communities</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for application and website owners to better curate their products and services around the needs of their visitors and those affected by what has been created and in doing so, reduce the ESG burden which can impact the sustainability of the website, especially around the Social (and user-experience) aspect.</p>
								<p>It should be noted that for machine automation, only quantitative feedback will be able to be processed (and therefore useful) and all information gathering must be done sustainably and ethically. It should also be noted that because information is being requested, internal access may be required to formally identify certain characteristics necessary for processing.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.hotjar.com/quantitative-data-analysis/software/">Quantitative data analysis</a> allows you to identify how your website or application is doing, find patterns in visitor behavior, and make decisions that can benefit your visitors and optimize your product or service to reduce emissions over time.</li>
									<li><a href="https://www.nngroup.com/articles/user-feedback/">Feedback forms</a> are a great way to get qualitative measurements to reinforce the numbers to ensure that any changes you are considering are wanted, satisfy the needs of visitors, and meet the sustainability challenge.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check to see if deliverables require internal access (if so, permission is given).</li>
									<li>Gather metrics data through browser APIs, analytics, or third-party software.</li>
									<li>Identify resolvable variables that are causing ESG issues.</li>
									<li>Once validated as accurate, test further using non-machine testable qualitative methods such as A / B measurement or feedback forms.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>If #1, #2 and #3 above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX02-2: Identify Visitor Constraints Using Browser Detection and the User-Agent -->
						<details>
							<summary>UX02-2: Identify Visitor Constraints Using Browser Detection and the User-Agent</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism so that websites and applications can offer contingency processes for visitors who have constraints such as an older device, an out-of-date operating system, an unusual or out-of-date browser, or a slow Internet connection. Other contingencies exist (such as geo-blocking or mobile data costs) and these can also be taken into account if detection is possible. Each of these issues can burden the user-experience and cause added conflict along the pipeline in terms of emissions.</p>
								<p>Once the constraint has been detected, it will often be up to the developer to create a solution that will involve compatibility features or reducing the load on the visitor's device to increase ease of access. If there are questions regarding the potential compatibility or availability of services due to a certain configuration, seek the manufacturer's advice for further guidance.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Browser_detection_using_the_user_agent">Using</a> <a href="https://developer.mozilla.org/en-US/docs/Web/API/Navigator/userAgent">UserAgent</a> to identify visitor characteristics that might impact their experience when using your product or service such as an issue of compatibility or performance.</li>
									<li>Certain political situations may result in the inability for visitors to access your product or service hassle-free such as geo-blocking restrictions, the cost of bandwidth, or government-enacted firewalls, filters, or authentication requirements.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that all visitor constraints have been detected.</li>
									<li>Ensure that a suitable solution is in place to handle each such event.</li>
									<li>Check other contingencies that may affect the availability of your product or service.</li>
									<li>Check if a solution can be offered for contingencies, otherwise, try working with partner groups to find solutions.</li>
									<li>Check that visitors can trigger the constrained environment manually.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX02-3: Test Against Specific Disability Profiles for More Calibrated Accessibility -->
						<details>
							<summary>UX02-3: Test Against Specific Disability Profiles for More Calibrated Accessibility</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to go beyond the remit of <abbr title="Web Content Accessibility Guidelines">WCAG</abbr> and accessibility by default and to encourage designers and developers of products to test their creations against a range of specific named types of disabilities to both better understand the conditions and to be able to more structurally and sustainably better test for the unique issues each disability brings to technology in terms of adaptation.</p>
								<p>It is strongly encouraged that teams work with individuals with disabilities when attempting this task as they will have the lived experience to help you better adapt your products and services to their needs. If this isn't possible or you wish to theorize against certain pre-built profiles, you can refer to established medical texts to identify potential symptoms and refer these against issues that may cause technology friction, building solutions, and / or simulators (see color blindness) to help test for issues along the creation process.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The use of a color-blind filter such as the one built into browser DevTools or another <a href="https://github.com/interaktivarum/rgblind?tab=readme-ov-file">third-party solution</a> potentially helps to identify contrast issues that might not otherwise be detected within an existing website.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Identify visitors or individuals with disabilities who can help you become more accessible.</li>
									<li>Create testable profiles from symptom / issue lists that cause friction.</li>
									<li>Check that potential solutions don't interfere with existing functionality.</li>
									<li>Create and implement newly calibrated accessibility features.</li>
									<li>Check that the features work as implemented against all existing functionality.</li>
									<li>Report the findings within your accessibility statement.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX03-1: Use Third-Party APIs To Measure Any Passive External Impact -->
						<details>
							<summary>UX03-1: Use Third-Party APIs To Measure Any Passive External Impact</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to utilize the tooling and resources provided by external parties to help you identify any efficiency and sustainability savings when having to use such services, or when non-digital forces come into play, such as if your product or service involves the physical delivery of goods.</p>
								<p>Getting the ESG equation of the sustainability of such forces can be difficult to track, especially as third parties may omit data or not provide a complete picture of their scope emissions. Therefore, care must be taken when choosing providers from the offset and consideration must also be given to the impact of using the API to gather such data together.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Using third-party tooling you can <a href="https://www.cocooncarbon.co.uk/">calculate</a> the carbon emissions from logistics and delivery of physical shipping which can be integrated into your calculations. They also have a <a href="https://developer.cocoonfms.co.uk/">public <abbr title="Application Programming Interface">API</abbr></a> you can use as well.</li>
									<li>Non-users who are affected by a service can be identified by technical support teams and responses required are added to a list for the developers to machine test for compliance at the next release version.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Identify providers who will offer transparent ESG measurements.</li>
									<li>Check the impact of utilization of third-party APIs (if possible).</li>
									<li>Check the impact of non-users or passive users affected by your service.</li>
									<li>Check that impacted visitors are accounted for in compliance checks.</li>
									<li>Report the findings within your sustainability statement.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX06-1: Measure Interaction Cost To Reach Every Page in the Information Architecture -->
						<details>
							<summary>UX06-1: Measure Interaction Cost To Reach Every Page in the Information Architecture</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to reduce the cognitive load for visitors between the initial visit to a website or application and reaching their final destination where the information they are seeking is located. The path to locating such information can be routed through multiple interactions such as a search mechanism, hyperlinks, form controls (where appropriate), and progressive disclosure features (reducing the complexity involved in reaching a destination will reduce the rendering load leading to sustainability benefits).</p>
								<p>While there is no hard and fast rule regarding the number of clicks required to meet a visitor's expectations, including clear way-finding (breadcrumbs can be machine-identified as can landing page regions to guide visitors along the path). It is therefore a sensible precaution to ensure that the steps required are well documented to avoid overwhelming a visitor. If required, click-through testing can be measured to identify bottlenecks in complex applications.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>While the <a href="https://www.nngroup.com/articles/3-click-rule/">three-click rule</a> is a false heuristic, employing common navigation patterns within a header or footer can help visitors traverse a product when multiple click-throughs are necessary to reach a destination faster.</li>
									<li>In complex websites, where multiple levels of documents and potentially thousands of pages may exist, <a href="https://blog.hubspot.com/marketing/navigation-breadcrumbs">having breadcrumbs</a> so that visitors can track their progress through the layers of a system (and even having dropdown navigation menus through each layer) can help with navigating the information architecture of a product or service with fewer barriers to access.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the information architecture has been designed with clarity in mind.</li>
									<li>Check the page for identifiable way-finding processes along a route such as breadcrumbs and landing regions / page patterns.</li>
									<li>Check that the number of choices for each action doesn't exceed a set amount.</li>
									<li>Check that every action is well documented and that the expected action occurs.</li>
									<li>Check the visitor flow path for achieving set goals and optimize with shortcuts if necessary.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX06-3: Check for Content Obscuring Materials That Occur Upon PageLoad -->
						<details>
							<summary>UX06-3: Check for Content Obscuring Materials That Occur Upon PageLoad</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that visitors can read the materials produced for your website or application and click on interactive content (such as links or buttons) that would otherwise be impaired by other content that due to positioning obscures the material by preventing the page from functioning correctly (wasted clicks, especially if JavaScript functions monitor them could lead to emission costs so its best to avoid unnecessary actions).</p>
								<p>There will be occasions when content should be obscured to progressively disclose additional content, but for unintentional overlapping, obscuring deliberately for attention (unnecessary), and all cases where the visitor did not ask to be impacted, the visibility of the content should be assured (either manually or mechanically through identifying object locations and dimensions plus where conflicts arise, issue remedial advice).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Advertising is often a cause of content that temporarily overlaps content with the intent of requesting clicks or attention-grabbing to monetize the material on the website or application. While such actions may be financially reasoned, they are rarely sustainably minded.</li>
									<li>Scrollable content in which the scrollbar has been obscured, replaced (with a non-functional, obscured, or hidden replacement), or hidden entirely making it impossible to detect where additional content may occur beyond just the window (such as in overflowing boxes) will be unavailable to visitors making its use of hardware to render a waste of resources.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check the page's content to ensure none is clipped by other materials or an overflow issue (with a scrollbar lacking).</li>
									<li>Check that all links and buttons are functioning.</li>
									<li>Check that progressive disclosing content only appears when requested.</li>
									<li>Check that necessary disclosing materials that obscure content can be easily removed.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX06-4: Break Large Pieces of Content Down Using Progressive Disclosure -->
						<details>
							<summary>UX06-4: Break Large Pieces of Content Down Using Progressive Disclosure</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to help increase the readability of content within a website or application by breaking down larger pieces of content into smaller constituent pieces. In the same way that a book is broken down into chapters, using progressive disclosure you can reveal sections when the reader is ready, avoiding information overload (the same can be done with long tasks).</p>
								<p>For machine testability, identification of such progressive disclosure markers can be found using the HTML details or dialog element, the CSS target selector (and its accompanying HTML ID attributes), the CSS checkbox hack, the use of JavaScript HashBangs, and also the use of state (and content) changes through various frameworks. Each of these can build a picture of how content displays on-screen during the user-experience, and some can load content only when it is requested which can reduce data transfer and rendering requests leading to sustainability improvements.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Tabs can be a simple way in which <a href="https://www.gov.uk/bank-holidays">you can showcase</a> different pieces of information to an audience. By using a mechanism such as the CSS target selector you can reveal information based on its related HTML ID.</li>
									<li>Dropdown menus such as the one you will find on many websites disclose from a single link several additional roadmapped locations which are grouped children in the information architecture of the product or service.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that progressive disclosure is used appropriately with your content or tasks to perform.</li>
									<li>Check that progress can be made from one disclosure to another.</li>
									<li>Check that each disclosure element can be closed successfully.</li>
									<li>Check that the disclosure method you use is compatible with visitor's browsers.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX06-5: Remove Any Non-User Initiated Pop-Up or Model Windows -->
						<details>
							<summary>UX06-5: Remove Any Non-User Initiated Pop-Up or Model Windows</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to reduce friction within the user-experience and help reduce the number of dark patterns which might occur onLoad and during the interaction process as these can cause considerable sustainability issues as a result of wasted emissions. By ensuring that the visitor remains in control of the interface and that websites and applications work as expected, a more ethical and optimized product or service is likely to result.</p>
								<p>Machine testing can analyze JavaScript for the use of popup events, the appearance of "_blank" within hyperlinks or frames, or other functionality that exists that may produce overlays. It's important to question the acceptability of such usage for example, opening links in new windows may be acceptable for non-web formats like PDF, otherwise, it's best to advise against its use.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>While not as common today, popup advertisements which appear in a new window or in a separate frame used to be a fixture of the early web and required heavy visitor management to close multiple banners that would trigger.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for CSS and JavaScript overlays that may occur onLoad and remove when identified.</li>
									<li>Check that any popup events can only be initiated with the visitor's consent.</li>
									<li>Check all hyperlinks for new window opening triggers (and action as appropriate).</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX07-1: Decorative Design Elements Can Be Disabled if They Are Not Done So by Default -->
						<details>
							<summary>UX07-1: Decorative Design Elements Can Be Disabled if They Are Not Done So by Default</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism in which visitors can reduce their impact by choosing to have a more basic experience (to what extent will be up to the developer) by downloading fewer external resources, scripts, and other assets to their machine to be processed and rendered. With this action, a website or application that is already optimized for sustainability can go one step further in providing a barebones format for those wishing to prioritize lowering their footprint over having added functionality.</p>
								<p>This action could be performed by defining what assets have been added to the product or service to enhance the experience but are not of critical importance (such as background images, or decorative flourishes that can be machine identified). Other forms of decoration can also be machine-identified such as CSS flourishes to content and images, background sounds, custom cursors, custom scrollbars, etc.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Web browsers can <a href="https://csscursor.info/">change CSS cursors</a>, and while there may be functional reasons to do so under certain circumstances, such as to indicate loading progress, zoom, or click-ability, in most circumstances, you should leave it at the system default as this is the expected behavior.</li>
									<li>CSS scrollbars <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_scrollbars_styling">can be customized</a> or replaced but this can be problematic for visitors. Changes in scroll speed or its mechanics can affect impact readability and the way things render, and color changes can impact visibility and affect overflow regions within elements of the page. In such cases, the system default always functions better than a custom solution.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check decorative images are clearly labeled using ARIA so assistive technologies can skip them.</li>
									<li>Check that CSS decoration can be disabled if it may interfere with readability.</li>
									<li>Check that custom scrollbars and cursors can be disabled as they may interfere with a visitor's ability to interact with the screen.</li>
									<li>Check that background sounds can be disabled and do not auto-load or auto-play.</li>
									<li>Check that decorative features can be disabled at the visitor's request.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX08-1: Making Your Navigation Menu Accessible and Well-Structured -->
						<details>
							<summary>UX08-1: Making Your Navigation Menu Accessible and Well-Structured</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to verify that your navigation menu is crafted in such a manner that it is both accessible to visitors and user-agents and functions correctly so that when implemented it doesn't lead to issues when attempting to browse the information architecture of a website or application. If the information architecture were to fail, this would lead to ESG failings as the social (human) aspect would no longer be able to use the product or service without encountering barriers to access and risk further emissions attempting to solve the issue.</p>
								<p>Machine testing the structure of a navigation menu will usually involve the nav, ul, or ol elements within the header of a product or service which repeats across pages and assuming that links function as expected and click ratios (sizes) are large enough on both desktop and mobile platforms, any search functionality will also need to be tested to ensure that results are provided upon submission.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The hamburger design is often considered the stereotype of <a href="https://www.smashingmagazine.com/2022/11/navigation-design-mobile-ux/">mobile functionality</a>, a three-lined icon that represents a menu upon clicking it reveals a full-screen list of options. Employing good patterns is key to reducing confusion and abandonment from visitors.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the structure of the navigation menu is semantically correct.</li>
									<li>Check that the structure of the navigation menu is repeated across all pages.</li>
									<li>Check that the click sizes / ratios of anchors in navigation menus are large enough on both mobile and desktop to be comfortable.</li>
									<li>Check that the URLs provided within links do not lead to errors.</li>
									<li>Check that any search functionality provides results (not errors) upon submission.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX08-2: Provide a Human-Readable Sitemap To Improve the Information Architecture -->
						<details>
							<summary>UX08-2: Provide a Human-Readable Sitemap To Improve the Information Architecture</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to increase the findability of the content within your website among search engines and social networks. By creating a <abbr title="Extensible Markup Language">XML</abbr> sitemap in the base directory of your website, and potentially having a human-readable) HTML sitemap to supplement it, you provide an index of all the publicly available pages. This acts as a potential signpost for individuals who may find themselves seeking information but not knowing exactly where it is stored.</p>
								<p>When creating an HTML sitemap it will be important to categorize pages into lists based on what section of the website they appear in (for human readability) rather than providing everything in a single long list. Structurally, you could use lists within lists to provide this distinction or use subheadings with individual lists. Both methods should ensure to be semantically correct and accessible to meet the social aspect of ESG targets.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The <a href="https://www.sitemaps.org/protocol.html">Sitemaps protocol</a> showcases a basic XML sitemap format that can be used within the base directory of a website. It is supported by search engines like Google and can be submitted for indexing which can increase findability and potentially help visitors find your product or service quicker.</li>
									<li>An <a href="https://www.semrush.com/blog/html-sitemap/">HTML sitemap</a> is a more visually organized showcase of the pages publicly available within your product or service. The idea behind it is to be as comprehensive as possible but not to overwhelm the visitor. This might be the ideal place to use a system like progressive disclosure so that you can guide individuals through the materials you provide interactively.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for a sitemap.xml file in the base directory of a website.</li>
									<li>Check that the markup of the file is semantically correct.</li>
									<li>Check that all of the links held within don't produce any errors.</li>
									<li>Check for the existence of a publicly visible HTML sitemap.</li>
									<li>Check that the file exists alongside a sitemap.xml format.</li>
									<li>Check that the HTML sitemap is semantically correct.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX08-3: Provide a Method of Keeping Up-to-Date With Product or Service Updates -->
						<details>
							<summary>UX08-3: Provide a Method of Keeping Up-to-Date With Product or Service Updates</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that visitors and users of an application or website can monitor changes and events that occur over time. The need to be able to track such events is critical as customers become reliant on products and services. This reliance on such features means that time will have been invested into learning how to set up and use the product, which if it fails could have a sustainability impact not just for the product or service owner, but for those reliant on its ability to function.</p>
								<p>Every product or service will have its own update schedule and there will be no hard and fast rule in terms of how often a website or application should be offering new releases. That being said, there should be a mechanism in place to describe news events both in a syndicated format and on the website, and a system status mechanism to identify any current issues with the product or service.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.apple.com/newsroom/">Apple has a newsroom</a> that is very minimalistic yet it contains all that you would expect from a news category from a major website. It has grouped stories with useful headlines, dates, categories, and a picture. Having something similar for your website can help visitors find new material quickly and reduce churn digging through archives.</li>
									<li><a href="https://www.w3.org/blog/feed/">Syndication feeds</a> come in multiple different formats but the most common is the <a href="https://www.rssboard.org/rss-specification"><abbr title="Really Simple Syndication">RSS</abbr> format</a>. They are compatible with readers on every platform and can be a useful way to get news to subscribers quickly. While these make regular requests to websites, they request less data and result in visitors spending less time browsing overall which is an emissions-positive event.</li>
									<li><a href="https://www.githubstatus.com/">System status pages</a> can be a useful customer metric for keeping up-to-date with ongoing issues and reducing the burden of customer support if something widespread happens to a product or service. It does produce reliance on a third-party but its sustainability benefits relate to the business governance and the data from the product can feed into improving ideation which can include improving all-round sustainability.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for a news page or category of a website.</li>
									<li>Check the news section has been updated within 12 months.</li>
									<li>Check for a syndication feed in RSS, Atom, or <abbr title="JavaScript Object Notation">JSON</abbr>.</li>
									<li>Check the syndication feed has been updated within 12 months.</li>
									<li>Check for other syndicated events (podcasts, <abbr title="Outline Processor Markup Language">OPML</abbr>, etc).</li>
									<li>Check the syndication feed is semantically correct.</li>
									<li>Check for a system status page and that everything is running correctly.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX09-1: Request Permission for Invasive Access To Interact With Content -->
						<details>
							<summary>UX09-1: Request Permission for Invasive Access To Interact With Content</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to use the least amount of permission requests required to achieve a given task. Allowing the visitor to control when they receive information is critically important but it's also important not to burden them with requests to access hardware or do things that might prove invasive (such as triggering notifications or a pop-up window).</p>
								<p>For mechanical testability, JavaScript APIs can check using methods such as requestPermission() to identify if a website or application has been granted access to use various hardware or potentially abusable features within the web browser. Unsubscribe, and delete / freeze account links could also be identified (with internal access being granted).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Cookie notification messages are required by law (the <abbr title="European Union">EU</abbr> Cookie Directive) and could be identified by a script. These are heavily featured within websites and allow visitors to prioritize privacy over the availability of functionality assuming that they are implemented correctly.</li>
									<li>Customizing or removing functionality within applications can help simplify the workflow of a visitor and increase the productivity within an interface (which will have sustainability benefits as it could reduce the weight from unnecessary features loading and visitors spending less time at the screen).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check which permissions from the available APIs are being granted.</li>
									<li>Check if products or services have unsubscribe / account freezing and removal options.</li>
									<li>Check if cookies are used and if so, if notifications are triggered appropriately (with the option to disable all).</li>
									<li>Check if applications plug-in functionality and allow for customization.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX09-2: Encourage Features That Reduce the Friction When Achieving Tasks -->
						<details>
							<summary>UX09-2: Encourage Features That Reduce the Friction When Achieving Tasks</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to lower the barriers to entry with content. When dealing with complex, multi-page websites it becomes increasingly important to have features in place to allow visitors to bypass repeated elements that they have already prefilled to achieve goals quicker (this is a key variable for sites who have large membership numbers).</p>
								<p>There are functional ways to increase the flow through a website and allow visitors to accomplish a task that can also be machine-testable. This technique is most useful when dealing with complex pieces of content, multi-step products, or services that have a lot of functionality that may require shortcuts to allow faster decision-making under certain conditions.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://goodlinks.app/">Read-It-Later</a> software may be provided by third-parties but they allow for both offline access to content on a variety of platforms and customization of the materials visually based on the visitor's requirements.</li>
									<li>Quick purchase features (such as Amazon's famous "Buy Now" button) allow for the immediate purchase of a product, skipping past the shopping basket steps and using prior purchase knowledge to reduce friction.</li>
									<li>Shortcut links and patterns can be used to skip ahead or over information and / or pages when it is recognized that the information may not be relevant or required in a multi-step process (such as form filling).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for read-it-later compatibility within articles.</li>
									<li>Check for purchasable products and the option to quickly purchase (bonus points if no login is required).</li>
									<li>Check if the HTML head contains landmark links of relevance to be identified.</li>
									<li>Check for recognized landmark shortcuts (skip links, etc) and that they are functional.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX09-3: Avoid Mechanisms That Promote Excessive Screen Time -->
						<details>
							<summary>UX09-3: Avoid Mechanisms That Promote Excessive Screen Time</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to allow the visitor to achieve the task they initially set out to do and not trigger unnecessary friction in the user-experience which would undermine their ability to complete the said task. Issues such as infinite scrolling can promote a need for continued browsing (which can load excessive data and have a sustainability impact on rendering) and loading overlays that deviate visitors from their path will have wider societal impacts on ESG targets which need to be considered.</p>
								<p>Within this technique, machine testability can be considered by examining if common link pagination landmarks (previous, next, &lt;numbers&gt;, etc) exist within category listings and if overlays or attention-keeping features are detected for common patterns (such as those mentioned in the examples below). If screen addition mechanisms are determined to be in use within a website, this should be considered a failing mark against the related success criteria.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Sale promotional overlays are a common theme that displays upon loading a page and requests the visitor take notice of them before dismissing them to view the content they want to examine.</li>
									<li>Information request overlays are another model window that often appears during a browsing session such as requesting your email address for a newsletter or your details to encourage sign-up after a timed period.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if infinite scrolling is being used through pagination landmark links.</li>
									<li>Check for recognized attention-keeping patterns that obscure content.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX10-1: Build Using Established Design Patterns That Use Known Conventions -->
						<details>
							<summary>UX10-1: Build Using Established Design Patterns That Use Known Conventions</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to use repeating patterns that visitors are likely to recognize from visits to other websites to build a sense of comfort and identification with your products and services. By using established design patterns that are repeatable, recognizable, and testable, you can reduce the amount of confusion likely to occur within a user-interface and this will increase the speed of adaptability (which has sustainability benefits).</p>
								<p>It should be noted that for machine testability, heuristic recognition (identification of patterns in code) will likely allow product creators to recognize the implementation of certain patterns, especially when libraries or design systems are utilized as the backbone of a product or service. Through this, recommendations can be made to improve layouts.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>A website layout could follow a <a href="https://htmlburger.com/blog/website-layout-ideas/">conventional design pattern</a> aimed at a recognized reading flow such as the F or Z pattern. They are based on established scientific studies of how people first identify and then read content on a screen. The mechanics behind such layouts are designed using CSS and can be identified based on the grid or flexbox pattern used to reduce the time visitors spend scanning the screen.</li>
									<li><a href="https://ui-patterns.com/patterns">Individual components</a> that aim to be repeatable conventions across products and services can take many forms (some are often provided as third-party services due to the build complexity involved) and should aim to be visually recognizable even if stylistic differences occur for branding which will help reduce wasted screen time.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for common in-page design patterns or libraries.</li>
									<li>Verify page components and overall design against established conventions.</li>
									<li>Check for and implement solutions for layout flow issues that could be optimized using an established pattern.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX11-1: Eliminate Deceptive Design Patterns or Manipulative Techniques -->
						<details>
							<summary>UX11-1: Eliminate Deceptive Design Patterns or Manipulative Techniques</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to prevent the visitor from being manipulated being a recognized dark pattern that falls under the umbrella of deceptive design. While there are a large number of ways to code ethically, using any one of these named practices would constitute a failure against WSG guidelines and as such, ensuring that practices are not used is worthy of inclusion.</p>
								<p>Machine testability for deceptive patterns will vary based on the type in use however the potential to integrate artificial intelligence to assist with more subtle uses of manipulation within tooling could be used. More obvious issues derided from code injection can be flagged and reported as problematic.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Disabling interface functionality such as the ability to highlight / select the text, right-click on content, copy the content to the clipboard, print, or paste passwords from management software can cause significant friction.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for bad practices such as those mentioned in the examples.</li>
									<li>Check against a library of <a href="https://www.deceptive.design/">deceptive design</a> patterns.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX11-3: Determine if Analytics Can Be Sustainably Improved or Removed -->
						<details>
							<summary>UX11-3: Determine if Analytics Can Be Sustainably Improved or Removed</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to eliminate the ESG social (third-party emissions, privacy, and performance) issues that relate to the use of analytics software. While this technique doesn't advocate that such software needs to be removed in all instances, the potential to flag poor-performing options and recommend more optimized solutions (or request removal) will be recommended.</p>
								<p>This should take into consideration the need for analytics in other success criteria (for research metrics) before recommending removal and identifying low-carbon options for third-party solutions (where data exists). Additional criteria based on ESG values (such as privacy and security) should also be considered.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Some <a href="https://dodonut.com/blog/best-ga4-alternatives-for-2023/">analytics providers</a> have made steps to become more sustainable which would potentially make them a better replacement for bulkier, more intrusive packages.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check to determine if an analytics script is being used within the page.</li>
									<li>Check against a list of suppliers of software to determine viable alternatives.</li>
									<li>If no viable alternative exists and it still performs poorly, recommend removal.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX11-4: Eliminate Any Manipulative SEO Techniques From Your Source Code -->
						<details>
							<summary>UX11-4: Eliminate Any Manipulative <abbr title="Search Engine Optimization">SEO</abbr> Techniques From Your Source Code</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to proof your code and content for practices that might detract from the user-experience but are done, purely in an attempt to gain higher rankings from within search engines. While getting such a position would be beneficial, using such techniques will often get the reputation of your site on these services tarnished and your rank will suffer significantly.</p>
								<p>Your visibility in search engines and social media matters. Visibility is how people find you on the web. If people cannot find you or sections of your website or application, they will consume resources in that effort (or trying to find a replacement). Additionally, bad SEO practices targeting only machines consume visitor resources for rendering and produce excess emissions.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Keyword stuffing is a practice in which the terms you want to be recognized for get repeated throughout your documents. While mentioning it occasionally is good, going over the top can hurt readability and bloat pages further, which is why it isn't considered sustainable.</li>
									<li>Hiding content, for example, using small font sizes, making the text the same color as the background, hiding text behind images, or generating CSS or JavaScript content purely for search engines is considered bad practice.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for the keywords <abbr title="Metadata">META</abbr> tag and recommend its removal.</li>
									<li>Check for the refresh META tag and recommend replacement with a page redirect header.</li>
									<li>Check for hidden content as identified in the above example and promote visibility or removal.</li>
									<li>Check for duplicate content and flag it for removal.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX12-1: Provide Deliverables in Reusable, Self-Isolated Components -->
						<details>
							<summary>UX12-1: Provide Deliverables in Reusable, Self-Isolated Components</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to allow for code that has been produced for an individual project to be re-used and reapplied across future work to reduce redundancy. This is most commonly seen in frameworks and libraries but isn't limited as such and can also apply to documentation and snippets.</p>
								<p>This technique is most useful when it is housed within an open source location to foster a culture of contribution, remixing, and improving of the work. While machine testing of code to determine functionality based on its apparent need would prove problematic, the ability to use importable code can be verified.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>A library like <a href="https://getbootstrap.com/">Bootstrap</a> can be imported as a whole into a project, but it can also be stripped back, eliminating all but the components that are in use by the website or application powering its functionality.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check to see if deliverables require internal access (if so, permission is given).</li>
									<li>Check to determine if these deliverables are housed in an open source environment.</li>
									<li>Check projects for multiple CSS files (or use of @imports).</li>
									<li>Check JavaScript for the use of imports or self-isolating functions.</li>
									<li>Check documentation for section separation as markdown files.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX12-2: Provide Documentation To Guide the Deliverables -->
						<details>
							<summary>UX12-2: Provide Documentation To Guide the Deliverables</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to guarantee that those without a working knowledge of an aspect of design or development will be provided with the information they require so that they can safely work with the files being presented to them during the creation and maintenance process.</p>
								<p>Because emissions do not start or stop at website usage, and emissions are created during the ideation and creation process, it is crucial that all involved with the project, even clients who may not be used to the types of technology to which this specification refers to, can optimize their ability to produce high-quality output, as this will reflect in sustainable websites and applications.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Many large projects have manuals or documentation that describe in detail how to work with the creations of a group of people either during the handoff (from one department to another) stage or during the completion (from the creators to the clients) stage.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check to see if deliverables require internal access (if so, permission is given).</li>
									<li>Check that the instructions, manual, or documentation exist.</li>
									<li>If the documentation does not exist, flag a request to produce materials.</li>
									<li>Check for multiple format types such as HTML, PDF, checklists, slideshow, and video.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX12-3: Create Code Comments To Describe the Functionality of Features -->
						<details>
							<summary>UX12-3: Create Code Comments To Describe the Functionality of Features</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide internal or external developers with the information they require to understand the justification behind certain coding choices, and what individual pieces of code exist for. While such features can be itemized within the documentation, code comments are useful for providing a portable library of notes with the source code itself.</p>
								<p>Every language will have its own descriptive mechanism for producing code comments and developers should prescribe to such best practices. Conventions could be utilized within comments such as including links to provide added context. Comments can be machine-detected by their opening and closing statements and paired with the code that follows them.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>In the source code for <a href="https://swhook.com/">Semantic Web Hook</a>, code comments are available for the un-minimized version to help developers identify the purpose behind each function (so they can decide if they require it).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for code comments within the source code of pages.</li>
									<li>Check the formatting of comments for conventions such as links, images, and bullets.</li>
									<li>If publicly facing, flag it for removal, if internal access is required or a developer release, keep it in place.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX13-1: Implement an Up-to-Date Design System -->
						<details>
							<summary>UX13-1: Implement an Up-to-Date Design System</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that stylistic choices made by the design and development team are based upon prescribed defaults. This will encourage consistency not just within the layout but also in terms of writing style, accessibility, sustainability, and other variables being monitored.</p>
								<p>There are already several established <a href="https://designsystemsrepo.com/design-systems/">design systems</a>, which provide a <a href="https://www.invisionapp.com/inside-design/guide-to-design-systems/">good baseline</a> for what should should be included within them. Either deploy an existing open source solution or craft a custom model that meets the needs of your product or service. Machine testability will rely on identifying the design system and then verifying the materials are being used in the wild.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://atlassian.design/">Atlassian Design System</a> breaks its library down visually on the main page to give new readers a great roadmap for where reusable components can be located and how everything should be represented.</li>
									<li><a href="https://carbondesignsystem.com/">Carbon Design System</a> provides dropdown menus of its entire library of components to allow visitors to quickly and easily access the elements they require, with a firm focus on being an open source project.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for the implementation of a design system.</li>
									<li>Check what number of categories being monitored.</li>
									<li>Check if the patterns and tokens are being employed.</li>
									<li>Check when the design system was last updated.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX14-1: Increase the Readability of Content Using Common Metrics -->
						<details>
							<summary>UX14-1: Increase the Readability of Content Using Common Metrics</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to make the content within your website or application more legible to individuals who may struggle with more technical language. Techniques such as lowering the reading age, removing industry terms (or clearly defining them), and having translations for international audiences can help get your message across and reduce on-page friction.</p>
								<p>This technique is most useful when dealing with a large body of content that the visitor has to wade through to complete a task. Being able to reduce screen time by improving the ease at which visitors can comprehend a topic will ultimately allow for an experience that feels faster and discriminates less against individuals who may struggle with highly technical content.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://tfl.gov.uk/info-for/suppliers-and-contractors/digital-design-toolkit/using-plain-english">Transport for London</a> has an editorial style guide that sets out to use Plain English throughout their website. The guide itself serves as a useful tool that others could adapt (including the terms in machine testability).</li>
									<li>There are lots of technical terms used in (for example) the Web industry, Jens Oliver Meiert has created the <a href="https://webglossary.info/">Web Glossary</a> as a dictionary of terminology which can help clarify confusing terminology.</li>
									<li><a href="https://readabilityformulas.com/readability-scoring-system.php">Readability Formulas</a> have an assessment tool that can use one of several different models to identify issues with content. As there is no agreed-upon assessment model, this can be particularly helpful.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check against a list of terms for the use of Plain English.</li>
									<li>Check that terminology is inclusive and non-discriminatory.</li>
									<li>Check that technical terms are identified and well-defined.</li>
									<li>Check that the content has an appropriate reading age.</li>
									<li>Check for internationalization within content, HTML, and CSS.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX14-2: Break Long-Form Content Down Into a Simpler Structure -->
						<details>
							<summary>UX14-2: Break Long-Form Content Down Into a Simpler Structure</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to avoid visitors being hit with a wall of text which risks abandonment of the page (and a wasted session with emissions attached). By taking large pieces of information and structuring them into more clean smaller chunks and utilizing a range of more friendlier features when appropriate such as lists and tables, the information will look less intimidating.</p>
								<p>For machine testability, identifying clear headings, visual hierarchy, spacing, line breaks, lists, use of images, and other features of HTML can help calculate the relative density of the content and whether it could be better presented not just for readers but to (if used with progressive disclosure) reduce the initial impact on rendering engines which can have a sustainable impact on hardware.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>This article from <a href="https://www.nngroup.com/articles/formatting-long-form-content/">Nielson Norman Group</a> provides some great examples and ideas around the subject of dealing with long-form content on the Web, each of which can be both implemented and tested against.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the heading hierarchy structure is correct (H1 > H6).</li>
									<li>Check that paragraphs don't exceed a set word length.</li>
									<li>Check the spacing between elements isn't too crowded.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX14-3: Produce a List of SEO Considerations To Improve Your Findability -->
						<details>
							<summary>UX14-3: Produce a List of SEO Considerations To Improve Your Findability</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to reduce the amount of time visitors and potential visitors spend churning through data attempting to locate you (or pages relating to you) through search engines or social media. These types of requests have an emissions impact from the hardware used to deal with the requests to the rendering of the results, therefore getting the right information to visitors as quickly as possible is critical to having a sustainable product.</p>
								<p>This list should be created as early as possible but could be machine-generated from a pre-determined list of SEO variables. The content of this material could be machine-tested against using automation if the variables can be aligned with what has been implemented. Additionally, publicly-facing social media handles that are identified within a product or service website can be detected.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.semrush.com/blog/seo-checklist/">SEMRush</a> has produced a checklist of SEO considerations which is based on their years of industry experience. While not everything will be able to be tested against, it's good to consider to improve overall visibility.</li>
									<li><a href="https://ahrefs.com/blog/seo-checklist/">AHREFs</a> have created a checklist that contains a lot of advice and tips on SEO. This list also has some components which aren't testable but the advice could also lead to sustainability benefits as a side-effect.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check against an SEO checklist for the state of a product or service's visibility (internal access may be required).</li>
									<li>Check for the website or application's position in major search engines.</li>
									<li>Check for social media handles and when they were last used.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX15-1: Implement a Range of Images of the Appropriate Format and Size -->
						<details>
							<summary>UX15-1: Implement a Range of Images of the Appropriate Format and Size</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective for this technique is to identify whether the images you are using are firstly necessary (which may be difficult to machine test), and secondly are using a format that is web appropriate. While these considerations may seem small they can dramatically lead to performance benefits that can reduce loading times and page bloat (which is an increasing issue on today's Internet).</p>
								<p>Implementations should consider in necessity the total image count (too many over a certain ratio could be problematic for those with bandwidth limits). Machine testability for web graphics can easily detect older formats that should be replaced immediately, formats that could potentially be changed for optimization purposes, and formats that could become vector graphics.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Certain image formats perform better than others, <abbr title="AV1 Image File Format">AVIF</abbr> and WebP will (in most cases) have better optimization rates than the original three classics for the web (<abbr title="Portable Network Graphics">PNG</abbr>, <abbr title="Joint Photographic Experts Group">JPEG</abbr>, and <abbr title="Graphics Interchange Format">GIF</abbr>) and should be considered by default.</li>
									<li>Different devices have different breakpoints, but these shouldn't be used as hard and fast rules for every situation as there are far too many devices out there to be compatible with. It makes better sense (if serving a single image) to default to the mid-range of the average device you receive.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check the image density of the page and flag pages over a certain image count.</li>
									<li>Check for older image format usage (<abbr title="Bitmap">BMP</abbr> / <abbr title="Tagged Image File Format">TIFF</abbr>) and require replacement.</li>
									<li>Check for PNG and JPEG images and flag potential upgrades to AVIF or WebP.</li>
									<li>Check for GIF and flag static image upgrade to AVIF or WebP, or animated images to mp4.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX15-2: Optimizing All Image Assets for a Variety of Different Resolutions -->
						<details>
							<summary>UX15-2: Optimizing All Image Assets for a Variety of Different Resolutions</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that images are not only served at the correct resolution and size for the device requesting them but also to make sure that the images being served have been compressed using a suitable algorithm to provide the asset at the lowest bandwidth requirements possible to the visitor, thereby improving multiple ESG variables and increasing performance.</p>
								<p>Compression tests can be run against every image to see if improvements can be made (above and beyond changing formats) without losing too much image quality that visibility becomes degraded and therefore a recognition issue. The use of the sizes attribute can also help provide alternative images for different resolutions as required by device requirements (though the default image should be set to a median value to balance size and weight).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.debugbear.com/blog/responsive-images">DebugBear</a> showcases how responsive images can be used to provide not just different optimized formats (for better compression) but different sizes to reduce the performance load on visitor's machines.</li>
									<li><abbr title="Mozilla Developer Network">MDN</abbr> has a section on <a href="https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images">responsive images</a> that goes into detail (with examples) showcasing how they can be created to work well across a variety of different platforms using the HTML IMG element.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for compression potential against every available image asset.</li>
									<li>Check CSS media or container queries to recreate different breakpoints in the design to identify and create the sizes of images required.</li>
									<li>Check for the use of the sizes attribute to provide responsive images.</li>
									<li>Provide optimized solutions if image problems have been detected.</li>
									<li>Check that the default image value is set to a median value.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX15-3: Include Lazy-Loading With Images That Load Below-the-Fold -->
						<details>
							<summary>UX15-3: Include Lazy-Loading With Images That Load Below-the-Fold</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to prevent image assets included within a website or application that are either visually below the fold or hidden due to progressive disclosure from being loaded until they appear in view of the visitor's screen. This can save bandwidth and the resulting processing of the image at the client-side which otherwise would occur and may not even be used if the visitor chooses to click elsewhere or close before reaching it.</p>
								<p>While it is preferable that only links below the fold have lazy-loading attached to them, there does not appear to be a penalty for including it within all images so if machine testing cannot differentiate this shouldn't be discriminated against as a failing point. Additionally, the point of the fold can change based on the type of device being used so it's worth considering this into processes.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://mathiasbynens.be/demo/img-loading-lazy">Mathias Bynens</a> created a <a href="https://web.dev/articles/browser-level-image-lazy-loading">lazy-loading</a> demonstration that showcases the technique being used in the wild. As you scroll down the page of the website, more of the images will be loaded on demand.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for the position of the fold on the smallest screen size visitors use.</li>
									<li>Check for lazy loading attributes against all images falling outside these dimensions.</li>
									<li>Check for lazy loading attributes against all images in progressive disclosure boxes.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX15-4: Provide the Option for Images To Be Disabled or a Low Fidelity Alternative -->
						<details>
							<summary>UX15-4: Provide the Option for Images To Be Disabled or a Low Fidelity Alternative</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that visitors with bandwidth restrictions or slow connections are given a mechanism to access your content when their ability to access critical information may be stressed. Providing such options may include an in-page solution (either by default or by choice), or through the offering of a highly optimized alternative for such requests.</p>
								<p>When providing such requests through a secondary stream (such as a low-fidelity option), this channel mustn't become as bloated as the primary channel. As such, guidelines should be drawn up regarding what can and cannot be included to ensure limitations are placed to maintain a basic level of service while not offering the full capability of the primary product.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://text.npr.org/">NPR provides a text-only version</a> of their main website to offer a basic level of service for those who may wish to access their services but have limitations on what they can access. As such, everything has been stripped back providing no interactivity, features, or other distractions.</li>
									<li><a href="https://lite.cnn.com/">CNN provides a lightweight version</a> of their website which does request cookie permissions (for analytics?) but the content is free of images, videos, and other components that can be render-blocking.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if an in-page "Lo-Fi" or "Eco mode" option exists, if by choice, recommend by default.</li>
									<li>Check for a low-fidelity / text-only / lightweight subdomain or path.</li>
									<li>Check that the low-fidelity option is at least 75% lighter than the main website.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX15-5: Add Details About Image Impacts to the Media Management and Use Policy -->
						<details>
							<summary>UX15-5: Add Details About Image Impacts to the Media Management and Use Policy</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that you provide details about any image reduction targets and techniques within a publicly available media management and use policy. This will help you to establish the criteria you will attempt to meet across your product or service and allow visitors to identify any failings if they spot them (which can be fixed during the product lifecycle).</p>
								<p>Machine testability for such processes can involve first ensuring that the media management and use policy exists and then checking for a section on images that exists can be a definable way of identifying that the subject is being mentioned. Content can be checked for accuracy through auditing processes and failings flagged up as issues requiring resolution to maintain compliance.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://sproutsocial.com/insights/social-media-policy/">Sprout Social</a> has a toolkit that guides you through the creation of a social media policy, which could easily be adapted to include ethics and ESG factors like sustainability within its criteria (under legal guidelines).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for media management and use policy existence.</li>
									<li>Check for a section on images to verify impact coverage.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX16-1: Remove Any Functionality That May Trigger Auto-Playing Animation -->
						<details>
							<summary>UX16-1: Remove Any Functionality That May Trigger Auto-Playing Animation</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that media will only run within a website or application on the command of the visitor and not begin consuming resources and thrashing hardware from the immediacy of the page load event. Because this involves HTML (attributes and background media), JavaScript, and images (animated <abbr title="Graphic Interchange Format">GIFs</abbr>), a multi-functional approach is required.</p>
								<p>Because media can involve audio and video, implementors will need to ensure that both are treated with equal respect as they both consume resources and contribute to emissions (to varying degrees). Additional care will also need to be taken to identify background media and prevent its sudden onset unless the function of that page or application is to show a media file (with nothing else).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Advertisements are one of the most common forms of autoplaying media, they often appear as small boxes (<a href="https://www.wired.com/story/how-to-turn-off-autoplay-in-browser/">Wired is an example of this in use</a>). While muting the media may reduce noise pollution, it does not reduce the carbon impact of loading, rendering, and playing of the media itself.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for background media and prevent auto-playing upon page load.</li>
									<li>Check that media that is required to play as a function of the product is muted by default.</li>
									<li>Check for audio and video HTML elements and remove any autoplay true events.</li>
									<li>Check for custom audio or video players and flag auto-playing media.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX16-2: Optimizing All Audio and Video Assets for Speed and Compatibility -->
						<details>
							<summary>UX16-2: Optimizing All Audio and Video Assets for Speed and Compatibility</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that both the formats being used for media have widespread browser compatibility and that the audio and video being served have been compressed using a suitable algorithm to provide the asset at the lowest bandwidth requirements possible to the visitor, thereby improving multiple ESG variables and increasing performance.</p>
								<p>Compression tests can be run against every video and audio file to see if improvements can be made without losing too much quality that the artifact becomes degraded beyond usefulness. Audio and video formats to be embedded with browser compatibility issues can also be machine detected and recommendations for alternatives can be offered (and implemented).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.bbc.co.uk/iplayer">BBC iPlayer</a> is an on-demand platform that can change the quality setting of the video being streamed. The quality being applied also changes based on variables impacting the environment.</li>
									<li><a href="https://www.youtube.com/">YouTube</a> has a setting to alter the streaming quality of videos (where the quality can be lowered). Again this platform uses browser metrics to automatically adjust the stream quality based on the visitor's environment.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for compression potential against every available audio and video asset.</li>
									<li>Provide optimized solutions if audio or video problems have been detected.</li>
									<li>Check for third-party non-native media player usage and recommend native options (if possible).</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX16-3: Provide Facades for Streaming Media and Animated GIFs -->
						<details>
							<summary>UX16-3: Provide Facades for Streaming Media and Animated GIFs</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism that ensures visitors remain in control of when highly impactful (in terms of emissions) media begins to transmit to their devices. By having a static facade that upon clicking begins the render (and not simply hiding the video or audio element behind the static image), you ensure that the content has a lazy-load effect even if autoplay is not active (as pre-buffering may occur during the render process).</p>
								<p>Because there is no browser default method for facades (at the time of publication), identification of such events for machine testability will come down to them being clearly labeled using ID or class attributes (or through heuristic testing for an image that is either anchor linked or has a button attached with a JavaScript event handler to process the content switch).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Jason Knight has provided some <a href="https://codepen.io/jason-knight/pen/OJBjgNQ">simple but useful examples</a> of his own implementation of accessible HTML video facades which he developed as a solution to the performance (and sustainability) issues media can cause.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that no video or audio elements trigger content upon the page load.</li>
									<li>Check that any uses of the GIF extension are not animated by default.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX16-4: Optimizing All Media Assets for a Variety of Different Resolutions -->
						<details>
							<summary>UX16-4: Optimizing All Media Assets for a Variety of Different Resolutions</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that videos are not only served at the correct resolution but also to identify assets that can help visitors make decisions before choosing to load the main video as to whether the media is correct for them. The location of these links should be connected to the embedded media, and either replace the original video upon click or downloadable for the visitor (they should not increase the number of embeds).</p>
								<p>JavaScript can be used to detect the resolution of the device accessing the media and serve the correct media size for the visitor requesting it (ensuring smaller devices don't get larger media files). Regarding the types of links to be offered, they should provide the visitor with more choice in terms of the quality of the video being consumed or provide added context to its purpose.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The <a href="https://archive.org/">Internet Archive</a> provides downloadable media files in a variety of formats in addition to being able to stream. This helps reduce the repeat burden on servers and avoids page-reload rendering emissions.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the video assets are provided in a variety of common resolutions (which can be user-chosen).</li>
									<li>Check if clips or trailers are provided to give a shorter overview.</li>
									<li>Check if downloads are provided for repeat viewing.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX16-5: Add Details About Media Impacts to the Media Management and Use Policy -->
						<details>
							<summary>UX16-5: Add Details About Media Impacts to the Media Management and Use Policy</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that you provide details about any audio or video reduction targets and techniques within a publicly available media management and use policy. This will help you to establish the criteria you will attempt to meet across your product or service and allow visitors to identify any failings if they spot them (which can be fixed during the product lifecycle).</p>
								<p>Machine testability for such processes can involve first ensuring that the media management and use policy exists and then checking for a section on audio, video, or media, exists can be a definable way of identifying that the subject is being mentioned. Content can be checked for accuracy through auditing processes and failings flagged up as issues requiring resolution to maintain compliance.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://blog.hootsuite.com/social-media-policy-for-employees/">HootSuite</a> has a template that guides you through the creation of a social media policy, which could easily be adapted to include ethics and ESG factors like sustainability within its criteria (under a new section).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for media management and use policy existence.</li>
									<li>Check for a section on audio to verify impact coverage.</li>
									<li>Check for a section on video to verify impact coverage.</li>
									<li>Check for a section on media if the above doesn't exist to verify impact coverage.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX17-2: Measure and Respond to High-Intensity Animation Usage -->
						<details>
							<summary>UX17-2: Measure and Respond to High-Intensity Animation Usage</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to determine if animation usage within an application or website will diminish the user-experience. By calculating the number of animations that occur and identifying if this number firstly can be reduced and then running each of them individually and identifying if they cause lagging on lower specification devices, offering a resolution will help reduce the <abbr title="Central Processing Unit">CPU</abbr> and <abbr title="Graphics Processing Unit">GPU</abbr> burden which can consume vast visitor resources.</p>
								<p>It should be noted that the types of animations used can dramatically affect the rendering process. Certain CSS transitions and animations are more process efficient than others, and JavaScript animation can also have differing impacts on CSS in both the choice of animation and how it has been put together. This should be considered when testing to offer low-impact animations and effects.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Personal portfolios are an ideal place to showcase expertise and you have more liberty to experiment with technologies including animation, which is precisely what <a href="https://kentcdodds.com/">Kent C. Dodds</a>, <a href="https://sarahdrasnerdesign.com/">Sarah Drasner</a>, and <a href="https://una.im/">Una Kravetz</a> have done.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check both CSS and JavaScript for animations and calculate the number that exists.</li>
									<li>If too many (based on a justified value) exist, request the removal of the most impactful.</li>
									<li>Check if animation techniques can be replaced by more efficient methods.</li>
									<li>Check individual animations to determine if the CPU or GPU burden on devices is within safe limits.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX17-3: Include a Mechanism To Pause or Stop Page Animation -->
						<details>
							<summary>UX17-3: Include a Mechanism To Pause or Stop Page Animation</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism to bypass animated effects that may be included within the page of a website or application. The buttons provided must include a stop / opt-out button as a mandatory option but may also include an option to pause and restart play as optional elements. These buttons must be visible at page load and before animation starts thereby giving the visitor time to action them before effects begin.</p>
								<p>It is preferable that the buttons remain visible when scrolling the page however if the animation is restricted to a certain part of a page then the buttons can also be restricted to that region and be classed as passing the criteria. There should be one universal set of buttons for all animation rather than individual options for every effect (except media such as video).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>On the <a href="https://12daysofweb.dev/">12 Days of Web</a> advent calendar for web developers, there is a toggle that can be enacted to start and stop an animated snow effect. This is particularly great as the trigger is set to opt-in animation.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if the animation has a mechanism to pause or stop animation or effects.</li>
									<li>Check that the buttons load and give a grace period to the animation taking place.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX18-1: Provide Accessible Mechanisms Around Symbols in System Fonts -->
						<details>
							<summary>UX18-1: Provide Accessible Mechanisms Around Symbols in System Fonts</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to avoid rendering issues surrounding emojis and symbol typefaces based on the operating system an individual may be using or the localization of their device. This can inherently cause accessibility issues which can reduce readability as well as the aforementioned visual glitches that can potentially have an impact on system hardware.</p>
								<p>For machine testability, flagging of symbol fonts (and potentially Emojis where operating system compatibility differences may be an issue) will increase readability if resolutions are put in place. One consideration may be to avoid using symbol fonts without an explicit justification and to only use Emojis that have endured widespread operating system compatibility.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Because there are some issues surrounding <a href="https://www.tiny.cloud/blog/emojis-and-accessibility/">Emoji use and typography</a>, a guide has been put together showcasing examples of the issues that can prevent visitors from being able to make sense of the content.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that system fonts are replaced with accessible Emojis.</li>
									<li>Check that Emojis are implemented with compatibility in mind.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX18-2: Provide Only WOFF Custom Typefaces Within a Set Limit -->
						<details>
							<summary>UX18-2: Provide Only <abbr title="Web Open Font Format">WOFF</abbr> Custom Typefaces Within a Set Limit</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to optimize a typeface to ensure that when custom fonts are provided, they are implemented as sustainably as possible requiring the fewest amount of resources to download and render as possible. By placing restrictions on the number of custom typefaces and using a highly optimized format (hopefully subsetted), you will have a highly compressed file.</p>
								<p>Multiple variables will contribute to the size of a typeface, as such, it is difficult to simply specify a hard number to aim for, but if (for example) you aren't using international characters and you can subset your font, eliminating such waste could save precious resources from the fonts character table and reduce the file size considerably (reducing the system resource load upon rendering).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.colorfonts.wtf/">Color fonts</a> experiment with not just custom typefaces, but with fonts that have multicolor effects built into them. This expands their file size (and is one of many factors which can impact the rendering load).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the number of custom typefaces does not exceed five.</li>
									<li>Check that fonts are preloaded within the head of the HTML document.</li>
									<li>Check that no obsolete font formats are listed (such as <abbr title="Embedded OpenType">EOT</abbr>, <abbr title="TrueType Font">TTF</abbr>, <abbr title="Scalable Vector Graphic">SVG</abbr>).</li>
									<li>Check that fonts are only provided using <abbr title="Web Open Font Format 2.0">WOFF2</abbr> or WOFF as a fallback.</li>
									<li>Check that if a custom font is variable enabled (refer to font directory), remove other references (bold, italic, etc).</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX19-1: Ensure That Every PDF or Other Non-Web Document Has an HTML Alternative -->
						<details>
							<summary>UX19-1: Ensure That Every PDF or Other Non-Web Document Has an HTML Alternative</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to expand the compatibility of non-native Web documents and to reduce the reliance on proprietary formats which can become an issue for visitors who may not have access to the software required to view the documents in question (either due to cost, the time expense of installing additional software, or the format no longer being maintained).</p>
								<p>The alternative format provided should be in HTML as this can be marked up to be Web accessible (and as an open format it can be maintained to be sustainable to meet ESG targets). The choice of which format to use should be clearly identified both using text and (if possible) using iconography, and if a default format needs to be set, having the open format is best.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The book <a href="https://eloquentjavascript.net/">Eloquent JavaScript</a> has been written primarily in HTML but also has an offline compiled PDF, ePub, and MOBI version available for individuals who would prefer to make use of these eReader-safe formats.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that all non-native Web documents have an HTML alternative available.</li>
									<li>Check that available formats are clearly identified with text and / or icons.</li>
									<li>Check any generated HTML transcript meets the WSGs.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX19-2: Provide a Suitable Font Stack When Custom Typefaces Are Used -->
						<details>
							<summary>UX19-2: Provide a Suitable Font Stack When Custom Typefaces Are Used</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure cross-platform compatibility when custom fonts are utilized within a product or service. This should be done by providing at least three fallbacks across a variety of different desktop operating systems (Windows, Mac, and Linux), mobile platforms (Android and iOS), and finally offering a generic font family as a last resort to fall back upon.</p>
								<p>Machine testing for suitable typefaces will involve a list of Websafe fonts for each platform to ensure a high probability of compatibility. Statistics about the usage of each platform can be gathered from analytics packages and used to determine which operating systems require support, from there, using a list of pre-installed fonts listed as web-safe will help you define a sustainable stack.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.apaddedcell.com/web-fonts/">This guide</a> provides a solid overview of Websafe typefaces across a multitude of platforms and includes common software packages such as Microsoft Office (early versions) and even some versions of iOS.</li>
									<li><a href="https://www.cssfontstack.com/">CSS Font Stack</a> gives a list (with statistics) of Windows and Mac typefaces including their availability. It's particularly useful as it groups them based on the relative font family the typeface relates to.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check all custom fonts have a generic font-family.</li>
									<li>Check all custom fonts have at least three listed Websafe fallback typefaces.</li>
									<li>Check that all Websafe fallback fonts cover Windows, Mac, Linux, and Mobile.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX19-3: Provide Alternative Text or Figure Captions for Images -->
						<details>
							<summary>UX19-3: Provide Alternative Text or Figure Captions for Images</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that alternative text is available for descriptive images that are non-decorative and are important to the content of the website or application. Within HTML this can be provided either through the use of the alternative text attribute or through the use of figure captions (which are associated with an image providing added context).</p>
								<p>Machine testability should flag any IMG element that has no alternative text unless it exists within a figure element that contains a figcaption element. There may be cases for decorative purposes where images do not require alternative text, however, these (arguably) should be identified as such and accessibility aids given the notification they can skip over them rather than being ignored.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/figcaption">MDN provides documentation</a> and an example of how figcaption can be used to give contextual meaning to an image. While the example only uses an IMG element, you could embed a picture element for the same effect.</li>
									<li>Web Development magazine <a href="https://alistapart.com/">A List Apart</a> provides alternative text on its images to ensure that those using assistive technologies can read the content without missing out on the context that they can provide.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that all IMG elements contain ALT attribute text unless within a FIGURE element with FIGCAPTION.</li>
									<li>Check that SVG elements contain a TITLE and optionally a DESC element.</li>
									<li>Check that CANVAS elements contain alternative textual content.</li>
									<li>Check that all AREA elements (for MAP elements) contain ALT attribute text).</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX19-4: Provide a Text Transcription of Media Files in an Open HTML Format -->
						<details>
							<summary>UX19-4: Provide a Text Transcription of Media Files in an Open HTML Format</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to offer a transcript of the content of an audio file or video. This is especially useful within podcasts or shows that follow the linear progress of events that can be organized into chapters. How content is chosen to be written up is at the discretion of the author but to pass the criteria it must be accessible, understandable, and content complete.</p>
								<p>As with all generated external HTML documents, for machine testability (this will include other examples such as UX51), the generated content must itself pass the WSG guidelines in being sustainable (meeting the Success Criteria as an HTML document that generates emissions). The document can be tested against the techniques laid down in this reference.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The <a href="https://99percentinvisible.org/episode/roman-mars-describes-chicago-as-it-is/transcript">99% Invisible podcast</a> provides text transcripts of its episodes using a paper icon to indicate availability. The speaker is clearly identified within each episode and credits are also provided alongside.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for an HTML transcript either below the media file (labeled transcript) or linked to the media.</li>
									<li>Check any generated HTML transcript meets the WSGs.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX19-5: Include WebVTT Closed Captions, Subtitles, and Sign Language Support -->
						<details>
							<summary>UX19-5: Include WebVTT Closed Captions, Subtitles, and Sign Language Support</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to enhance existing media that has been provided to ensure maximum legibility and comprehension. In doing so, the viewer is less likely to have issues in which they rewind content to attempt to understand dialog which they had difficulty understanding (which will in turn cause bursts of CPU and GPU activity during this media manipulation).</p>
								<p>Layering additional context upon a video may initially have an additional outlay in terms of emissions (due to the loading of additional files or rendering extra content upon the screen) but because of its social and societal benefits, it meets ESG targets and as such should be prioritized. Testers should therefore seek to identify such features and flag non-availability as an issue.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://meryl.net/webvtt/">Meryl Evans has a great example</a> with some basic code (and links to further materials on using the WebVTT format for providing essential captioning for your videos. It's covered in <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebVTT_API">more depth on MDN</a>.</li>
									<li>Paying for a sign language interpreter for your videos can offer added value to your content. It can be easier to understand than written content, reduces accessibility friction, and increases satisfaction levels.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for iconography to identify sign language or accessible media aids.</li>
									<li>Check for the availability of a WebVTT file with video files.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX20-1: Detect Form Requirements and Identify Data Collection Policies -->
						<details>
							<summary>UX20-1: Detect Form Requirements and Identify Data Collection Policies</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to reduce the amount of friction that occurs when information is required to be entered on a form control within a user-interface. By identifying how many elements must be filled out (and those which are not mandatory being eliminated), clearly labeling how such components need to be filled out (and how many steps there are), plus having links to data collection policies, this friction can be substantially reduced.</p>
								<p>Reducing form friction can lead to less unnecessary data transmission which is not only beneficial in terms of privacy and security (the social component of ESG) but also having fewer form elements or steps to render will have an emissions reduction due to the lower amount of individual elements to render to the screen (and the visitor will spend less time on-screen filling the forms in).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Domain Registrar <a href="https://iwantmyname.com/support">iWantMyName</a> takes form filling to the most minimal extent possible on their contact page, only providing three essential fields to deal with requests, each of which is clearly labeled.</li>
									<li>The <a href="https://account.bbc.com/register">registration page for BBC iPlayer</a> is a multi-step process that is well designed and labeled to avoid overwhelming new users and it only requests the minimum amount of data necessary to set up an account.</li>
									<li>This <a href="https://symptomate.com/">medical diagnosis application</a> decides what information is required to be filled in next upon the previous submission, thereby only relevant questions are being asked (leading to less redundancy in form filling).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check how many steps there are in an input process and if this can be reduced.</li>
									<li>Check that all form components are clearly labeled and disclose their purpose.</li>
									<li>Check that only necessary form elements are displayed onscreen.</li>
									<li>Check that a publicly displayed data collection policy link is visible (this may be a section of a privacy policy).</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX20-2: Reduce Friction Within Data Entry With Automatic Assistance Settings -->
						<details>
							<summary>UX20-2: Reduce Friction Within Data Entry With Automatic Assistance Settings</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism within forms to reduce friction that might occur during necessary data entry. Such data entry will cause visitors to spend time onscreen and as such will generate emissions in addition to frustration from failed attempts leading to potential escalation of such emissions being triggered (while also conserving bandwidth).</p>
								<p>For machine testability, the autocomplete attribute should be disabled in all form inputs outside of those likely to be utilized / assisted by a password manager (this is especially true where the suggestions do not come from a visitor device but a third-party and additional bandwidth or rendering processes are likely to be endured). A list of such inputs can be identified from a common password manager and marked against each form for correctness.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.grammarly.com/signin">Login forms such as Grammerly</a> can be detected by password manager software and therefore have a benefit for autocompletion (as visitors cannot be expected to remember personal details across all websites).</li>
									<li><a href="https://www.jotform.com/form-templates/job-application">Filling in an application form</a> should allow autocomplete for elements of a profile that may be contained within a password manager (such as name, email, and phone), but should be disabled in all other formats to prevent the text element from attempting to anticipate the visitor's responses.</li>
									<li>The HTML Hell advent calendar has a <a href="https://www.htmhell.dev/tips/autocompleting-password-fields/">great article on providing autocomplete</a> for the sake of third-party tooling access such as password managers. It includes a range of examples and links to additionally useful articles that might guide decision-making.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that autocomplete is enabled in all username and password fields.</li>
									<li>Check that autocomplete is enabled in all identity (E.G. address, email) fields.</li>
									<li>Check that autocomplete is disabled in all other input fields.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX21-1: Provide Compatibility for Non-Visual Browsing Methods -->
						<details>
							<summary>UX21-1: Provide Compatibility for Non-Visual Browsing Methods</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for those not using a screen as a primary method of browsing to have an equal browsing experience. This is primarily due to screens being a high emitter of emissions in terms of energy usage, but also with the increase in speech-powered devices, the need for support mechanisms to be in place has increased in recent years.</p>
								<p>Detection of such support can be clearly identified with good semantics and high-quality content as a foundation, however for machine testability, thresholds such as having a speech stylesheet in place (that can help with issues around pronunciation and tone) and testing projects within text browsers for fundamental mechanical issues are critical to establish a pass.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The <a href="https://lynx.invisible-island.net/">Lynx text browser</a> is one of the oldest maintained browsers on the Internet and it can be particularly useful in identifying issues around keyboard navigation and non-visual browsing when features are unavailable.</li>
									<li>This <a href="https://www.smashingmagazine.com/2020/12/making-websites-accessible/">article from Smashing Magazine</a> describes in detail how websites and applications can make their work easier for non-visual devices such as speech environments (like cars and smart speakers) to access.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for a speech stylesheet for indicators to clarify pronunciation issues.</li>
									<li>Check that your website or application functions correctly in a text-only environment.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX22-3: Provide Error Detection When User Input Is Required -->
						<details>
							<summary>UX22-3: Provide Error Detection When User Input Is Required</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism to notify the visitor if an issue has occurred during the form-filling process that may be remedied either before or after the submission process has occurred to resolve the issue before it reaches its intended location. Providing error detection and assistance can reduce friction and screen time searching for answers.</p>
								<p>Machine testability for error detection would require the submission of dummy data (incorrectly) into a form of required elements to test the durability of the process to see if instructional recommendations are given. Such prompts that either correct or guide the visitor can be deemed to pass the Success Criteria. If no guidance is offered or if forms are incorrectly labeled, leading to errors, this would qualify as a failure as visitor friction will occur.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>This <a href="https://www.w3.org/WAI/WCAG22/working-examples/script-form-validation-2/index.php">example of client-side form validation</a> based on <a href="https://www.w3.org/WAI/WCAG22/Techniques/client-side-script/SCR32.html">WCAG Technique SCR32</a> showcases a classic example of error handling and how providing a response to the user input when failure occurs is important.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that HTML form components are correctly labeled (for example, required elements, and content types).</li>
									<li>Check that JavaScript error handling is provided for the client-side (pre-submission).</li>
									<li>Check that server-side error handling is provided for post-submission (no JavaScript) issues.</li>
									<li>Check that all prompts occur in a suitable location, relative to the error occurring.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX23-1: Add a Print-Friendly Media Query or Stylesheet -->
						<details>
							<summary>UX23-1: Add a Print-Friendly Media Query or Stylesheet</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to reduce the amount of excessive paper and ink resource mineral waste produced from the physical printing of documents by visitors of your products and services. By creating a customized print stylesheet you can optimize the use of these resources and improve readability of the layout if the document is exported into a static format such as PDF.</p>
								<p>This technique is most useful when it covers a lot of issues that physical formats can suffer over their digital counterparts (such as no interactivity), the necessity of color usage or content, breaks in flow and pages, etc. Machine testability can examine the stylesheet for such feature handling as compliance with Success Criteria (link expansion, paper size support, CSS resets, etc).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The <a href="https://printedcss.com/">Printed CSS Framework</a> contains a multitude of features intended to reduce the impact of printed media, with additional support for handling a range of special developer set cases that can be defined in HTML.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the website or application has a print-friendly media query (@print) or stylesheet.</li>
									<li>Check that the print CSS makes attribute content and URLs visible.</li>
									<li>Check that the print CSS considers content color accuracy and monochrome options.</li>
									<li>Check that the print CSS considers paper orientation, color, and size.</li>
									<li>Check that the print CSS hides unnecessary structural material.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX23-2: Optimizing All Document Assets Across a Variety of Different Formats -->
						<details>
							<summary>UX23-2: Optimizing All Document Assets Across a Variety of Different Formats</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that non-web documents are not only served in a range of compatible (suitable) formats for the device requesting them but also to make sure that the documents being served have been compressed using a suitable algorithm to provide the asset at the lowest bandwidth requirements possible to the visitor, thereby improving multiple ESG variables and increasing performance.</p>
								<p>Compression tests can be run against every document format to identify if improvements can be made without losing too much quality that visibility becomes degraded and therefore a recognition issue (in embedded images and media within). The primary format given to visitors should be the one with the widest compatibility for viewing within the browser plugin-free (usually PDF).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>A legal document that an individual will need to read through before potentially taking part in an offline process (that is partially handled online) may require such a process. Avoiding the necessity to download and install additional software wherever possible will reduce emissions.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the primary document format is the most browser-compatible.</li>
									<li>Check that more than one format is given if a non-Web format is offered for compatibility.</li>
									<li>Check for compression potential against every available document asset.</li>
									<li>Provide optimized solutions if document problems have been detected.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX23-3: Provide Document Details Including a URL Within a Page -->
						<details>
							<summary>UX23-3: Provide Document Details Including a URL Within a Page</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for individuals to access downloadable or embeddable documents without the material having been embedded within the document. Embedded content has an attributable carbon cost due to the rendering of the host applications processes as well as the content and there is a chance visitors clicked a link in error.</p>
								<p>Providing structural information about resources including direct links to files in preference to auto-loading content keeps the visitor in control, avoiding the loading and rendering of necessary resources. Machine testability of such components can test for embedded elements to avoid clearly marked-up document descriptions and direct URL links that are user-enacted.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Smashing Magazine provides a copy of their <a href="https://www.smashingmagazine.com/2021/01/front-end-performance-2021-free-pdf-checklist/">front-end performance checklist</a> in a multitude of formats, and this is described with direct links at the top of their open HTML version of the same document.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that document pages do not embed large files (internally or with third-parties).</li>
									<li>Check that document links are clearly described with information about name, format, language, size, and potentially a summary.</li>
									<li>Check for choice options with format and language variables in documents.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX24-1: Identify a Stakeholder-Focused Testing and Prototyping Policy -->
						<details>
							<summary>UX24-1: Identify a Stakeholder-Focused Testing and Prototyping Policy</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to identify the way new features, product ideas, and user-interface components will be tested among various stakeholder groups such as those with with accessibility issues. The main location for such an outline will be through a stakeholder-focused testing & prototyping policy and as such once implemented publicly, a link to the policy should be available.</p>
								<p>Machine detection could use heuristics to identify key policies within the text, however at a basic level, being able to identify the policy exists, potentially within the footer of a website or application along with other policies and legal documents, and then further analysis of individual headline elements of key sections of the document, should be enough to justify a passing criteria.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The <a href="https://www.gov.uk/service-manual/user-research/using-moderated-usability-testing">UK Government</a> has a publicly visible Usability Testing (User Research) guide within their service manual which outlines the processes they aim to follow when conducting such activities for their service.</li>
									<li>The <a href="https://www.st-andrews.ac.uk/digital-standards/policies/usability-testing/">University of St Andrews</a> has a publicly facing Usability Testing Policy that covers and applies to all staff that undertake usability testing at the campus at that university. It's well broken down and explanatory.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if a Testing policy is both published and publicly visible.</li>
									<li>Check for key policy factors are presented within the text (optional).</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX25-1: Produce a List of Checkpoints To Ensure Quality Control -->
						<details>
							<summary>UX25-1: Produce a List of Checkpoints To Ensure Quality Control</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to produce a comprehensive maintainable list of quality assurance lists across a range of different categories not limited to bugs, security, web performance, accessibility, sustainability, etc. By having this list in place, everyone involved in the creation process can closely monitor the application or website against each checkpoint to identify resolutions either before, during, or after a product or service is launched.</p>
								<p>This list should be created during ideation if possible but can also be machine-generated from a pre-determined set of lists relating to these topics based upon evidence and research. The content of this material can potentially be further tested through automation however at a bare minimum, this list must be utilized in-house to enact sustainable change. For machine testability, if this list is not publicly visible, internal access will be required to determine creation.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://developer.chrome.com/docs/lighthouse/overview">Lighthouse</a> is an open source project which enables both the auditing and production of reports of websites and applications for several common issues across a range of categories from within a web browser.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check to see if deliverables require internal access (if so, permission is given).</li>
									<li>Check that the testing regime is available (internally or externally).</li>
									<li>Identify all bug and security tests to perform during the testing process.</li>
									<li>Identify all web performance tests to perform during the testing process.</li>
									<li>Identify all web accessibility tests to perform during the testing process.</li>
									<li>Identify all web sustainability tests to perform during the testing process.</li>
									<li>Report and resolve the findings within your auditing process.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX25-2: Provide Active Monitoring for Issues on a Frequent Schedule -->
						<details>
							<summary>UX25-2: Provide Active Monitoring for Issues on a Frequent Schedule</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that problems relating to the sustainability of a website can be picked up with more frequency and regularity. Within the scope of website and application testing, it is important to be actively monitoring for common failure points that build over time and upon being notified of said issues provide resolutions within a reasonable timeframe.</p>
								<p>Machine testability for this implementation will be based on the mechanism used for testing. For instance, if a product or service provider chooses to simply run routine tests on a scheduled basis this may be considered a pass as long as the time between scans is frequent enough that it can be considered active in opposition to occasional (weekly would be the widest margin).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.speedcurve.com/">Speedcurve</a> is a commercial product that actively monitors websites for performance issues (broken down by category in rendering) and can provide advisory guidance on meeting targets for performance budgets.</li>
									<li><a href="https://search.google.com/search-console/about">Google Search Console</a> is a free product that monitors websites for issues that may affect their ability to be indexed within the Google search engine, which notably can impact their overall global page visibility.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that testing occurs hourly / daily / weekly to be considered active.</li>
									<li>Check that all publicly visible pages are included within the monitoring.</li>
									<li>Check that the facility providing the monitoring meets the WSGs.</li>
									<li>Check that a report of ongoing listed issues is publicly available until fully resolved.</li>
									<li>Provide resolutions for detected issues within a timely manner.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX25-3: Scan for Introduced Issues Upon the Completion of a New Release -->
						<details>
							<summary>UX25-3: Scan for Introduced Issues Upon the Completion of a New Release</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for eliminating any potential new flaws that may have been introduced into a website or application upon the release of a new version that will have additional updates or features that could break functionality if not implemented correctly. As such, enforcing a sustainability scan across a series of variables is critical.</p>
								<p>For machine testability, the necessity of automation of running a scan could be triggered on the publication of each new release, or for more nuanced control (where active monitoring already exists and non-breaking features are being introduced), a scan could be triggered only where only a major release is issued when breaking changes are more likely to occur.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.w3.org/WAI/test-evaluate/tools/list/">Accessibility scanners</a> can use the machine-testable elements of WCAG to help identify issues that can be resolved. While they aren't a silver bullet and cannot replace manual audits they can identify some issues.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that all publicly visible pages are included within the monitoring.</li>
									<li>Check for a wide variety of issues within the scope of the WSGs.</li>
									<li>Check that a report of ongoing listed issues is publicly available until fully resolved.</li>
									<li>Provide resolutions for detected issues within a timely manner.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX26-1: Establish Performance Testing Routines With Each New Release -->
						<details>
							<summary>UX26-1: Establish Performance Testing Routines With Each New Release</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to encourage a routine to improve web performance within websites and applications due to the established link between web performance optimization and digital sustainability. Running regular benchmarks and working from checklists (either prefabricated or built from scratch) will encourage a schedule to identify potential bottlenecks.</p>
								<p>The content of these testing routines can potentially be further tested through automation however at a bare minimum, this list must be utilized in-house to enact sustainable change. For machine testability, if this list is not publicly visible, internal access will be required to determine whether creation has taken place.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Smashing Magazine has a comprehensive <a href="https://www.smashingmagazine.com/2021/01/front-end-performance-2021-free-pdf-checklist/">front-end performance checklist</a> that could be utilized as part of a routine in release schedule checking for Web performance issues that may exist or have been introduced.</li>
									<li><a href="https://dev.to/ben/addy-osmanis-18-point-web-performance-checklist-2e1">Addy Osmani back in 2018</a> created an 18-point Web performance checklist that if you're looking for something more simplistic and rapid to compare builds against could potentially be very useful as a starting point.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check to see if deliverables require internal access (if so, permission is given).</li>
									<li>Check that the testing regime is available (internally or externally).</li>
									<li>Identify all web performance tests to perform during the testing process.</li>
									<li>Report and resolve the findings within your auditing process.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX26-2: Provide Compliance Checks With Each Release for Relevant Legislation -->
						<details>
							<summary>UX26-2: Provide Compliance Checks With Each Release for Relevant Legislation</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism during the development process where businesses and individuals creating Web projects can verify that new work meets compliance targets for individual regulations. This technique is most useful when performed with each major milestone as there is a potential for feature (and compliance) breaking material to occur.</p>
								<p>Within the scope of sustainability, this is increasingly important as there are explicit laws surrounding the subject in addition to expanded ESG remits such as accessibility, privacy, etc. In terms of machine testability the mechanics of an implementation may be more difficult than utilizing an automated checker, but wizard software can work through questions to help identify key issues.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Internationally reaching environmental legislation such as <a href="https://finance.ec.europa.eu/capital-markets-union-and-financial-markets/company-reporting-and-auditing/company-reporting/corporate-sustainability-reporting_en"><abbr title="Corporate Sustainability Reporting Directive">CSRD</abbr></a> and the <a href="https://www.europarl.europa.eu/news/en/press-room/20240112IPR16772/meps-adopt-new-law-banning-greenwashing-and-misleading-product-information">Green Claims Directive</a> provide stricter enforcement around product descriptions and the need to reduce emissions and accurately report such efforts.</li>
									<li>Accessibility legislation (<a href="https://www.w3.org/WAI/policies/">of which there are many worldwide</a>) provides strict enforcement around ensuring inclusivity not just offline but also in the digital sphere as well, leaving non-compliance open to lawsuit risks.</li>
									<li>Internationally reaching privacy legislation such as <a href="https://gdpr-info.eu/"><abbr title="General Data Protection Regulation">GDPR</abbr></a> can also impact digital services on a sustainability level (through the social aspect of ESG), and <a href="https://gdpr.eu/checklist/">various</a> <a href="https://gdprchecklist.io/">checklists</a> can assist.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check to see if deliverables require internal access (if so, permission is given).</li>
									<li>Check that the testing regime is available (internally or externally).</li>
									<li>Identify all relevant compliance checks to perform during testing process.</li>
									<li>Report and resolve the findings within your auditing process.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX29-1: Provide a Publicly Visible Compatibility Policy or Statement -->
						<details>
							<summary>UX29-1: Provide a Publicly Visible Compatibility Policy or Statement</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that visitors are made aware of (or able to find out) the limitations of a product or service before issuing a support request that will involve creating new emission sources. This compatibility policy can be listed amongst other policies on a website, however, it must contain detailed information about any factor that may have reduced capability.</p>
								<p>For machine testability, attempt to first establish that the policy exists and then try using heuristics (or identification of the headlines) to locate sections on what is both actively supported (those conditions tested upon), and those that are confirmed as unsupported (those conditions known to be broken but will not be fixed with reasons given). Ensure that a support method is also provided.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>British cellphone provider GiffGaff provides a <a href="https://www.giffgaff.design/guidelines/browser-support-policy/">web browser support policy</a> that identifies which browsers they support and don't actively support plus they also offer the <a href="https://www.giffgaff.io/tech/creating-a-browser-support-policy">justification behind their decisions</a>.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for a compatibility policy or statement's existence.</li>
									<li>Check for sections on included and excluded coverage.</li>
									<li>Check that a support method is offered for issues outside of scope.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX29-2: Provide Clarification When Updates Are Significant Over Minor Releases -->
						<details>
							<summary>UX29-2: Provide Clarification When Updates Are Significant Over Minor Releases</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for introducing visitors to new features and capabilities within websites and applications upon a major release being triggered. This would include compatibility changes, any alterations that affect workflow, and bugs that have been resolved. It applies equally to both applications on upgrade paths and website redesigns.</p>
								<p>The importance of re-orientating users around breaking changes is crucial as modifications made could lead to errors in usage, increases in technical support, friction in usability or accessibility, or introduction of issues that may lead to multiple impacting ESG factors that could be resolved through training, answered questions, and well-signposted information architecture.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Using <a href="https://semver.org/">Semantic Versioning</a>, providers through their release notes (which if publicly available could be machine tested against), could easily identify a major (breakable significant), against a minor (non-breaking) release.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for a publicly available change.log or release notes.</li>
									<li>Check that the frequency of updates has not been less than 12 months.</li>
									<li>Check that major releases provide details of breaking features.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX29-3: Establish Compatibility Testing Routines With Each New Release -->
						<details>
							<summary>UX29-3: Establish Compatibility Testing Routines With Each New Release</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that compatibility issues resulting from visitor constraints (such as operating system or browser age / connection speed, availability, or cost) are factored into the testing process at each new release. Creators must have processes in place whether through checklists that are pre-created or crafted from scratch to ensure that a regime is in place.</p>
								<p>In terms of machine testability, some tools can provide virtualized emulations of certain operating systems and thereby load products and services to undertake tests (or screenshots) to examine compatibility. Data also exists regarding mobile data charges and connection speeds which can be used to emulate or identify the compatibility costs associated with projects.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.browserstack.com/">Browser Stack</a> and <a href="https://www.lambdatest.com">LambadaTest</a> provide virtual testing (which can be automated) amongst a variety of common web browsers allowing testers to identify flaws in their website or application's compatibility.</li>
									<li><a href="https://whatdoesmysitecost.com/">What Does My Site Cost</a> calculates the amount of money a website will cost in terms of network fees to an individual around the world based on open data which can be a useful incentive to reduce excessive data use.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check to see if deliverables require internal access (if so, permission is given).</li>
									<li>Check that the testing regime is available (internally or externally).</li>
									<li>Identify all compatibility tests to perform during the testing process.</li>
									<li>Report and resolve the findings within your auditing process.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- UX29-5: Provide a PWA if More Suitable Than Its Native Counterpart -->
						<details>
							<summary>UX29-5: Provide a <abbr title="Progressive Web Application">PWA</abbr> if More Suitable Than Its Native Counterpart</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to identify a web application that exists and then determine if turning the web application into a progressive web application would be more beneficial than providing a native offering. This would need to take into account current web capabilities (such as ServiceWorkers), methods of delivery (such as <abbr title="Web Assembly">WASM</abbr>), and the human aspect (audience requirements).</p>
								<p>Machine testability can firstly examine the existing state of an application to determine how sustainable it is and what technology stack was used to develop it (and how sustainable it already performs for all), from there, data points can be used to identify an approximate cost of implementation for both a native or highly optimized web application endpoint and options can be provided.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Native applications may be a good choice if applications require specific access to hardware as Web APIs can still be quite restrictive. In addition, there is a case for going native to provide a more <abbr title="Operating System">OS</abbr>-centric look and feel.</li>
									<li>Web applications are often quicker and easier to deploy and can provide updates without delays in the pipeline (as they don't have to go through store controls), they can also benefit from lower creation costs.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if the existing application already utilizes a ServiceWorker.</li>
									<li>If so, check the PWA JavaScript and JSON are well formed, and the icon exists.</li>
									<li>If not calculate the sustainability impact of becoming a PWA.</li>
									<li>Check that no native application already exists (<a href="https://developer.apple.com/documentation/webkit/promoting_apps_with_smart_app_banners">meta tag smart banner</a>).</li>
									<li>If so use that, otherwise calculate the sustainability impact of building an application.</li>
									<li>If cost-efficient sustainability-wise, implement a PWA or / and a native application.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
				</ol>
			</section>
			<section> <!-- Web Development -->
				<h3><dfn data-lt="WebDev">Web Development</dfn></h3>
				<p>Each of the below can be shown or hidden by clicking on the technique you wish to display.</p>
				<ol>
					<li> <!-- WD01-1: Profile Existing Projects To Identify Common Variables of Value -->
						<details>
							<summary>WD01-1: Profile Existing Projects To Identify Common Variables of Value</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to identify any technical indicators which may be of use within a sustainability budget or those that can be immediately identified as exceeding a recommended level for an average page size thereby indicating that the document should be split or broken down into either two or more pieces to reduce the impact of the experience upon the visitor.</p>
								<p>Factors that may be taken into account could include an extremely long document that would require excessive scrolling (based on either the visual spacing or the number of <abbr title="Document Object Model">DOM</abbr> elements involved), the number of DOM elements could also be a factor as too many could produce unwarranted rendering loads, also excessive <abbr title="Hypertext Transfer Protocol">HTTP</abbr> requests can produce a lot of overhead.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Websites that need to display a large number of icons may choose to bundle the <a href="https://levelup.gitconnected.com/build-an-icon-system-with-svg-sprites-a-complete-guide-1e195820ac6a">vector images into a sprite</a> which avoids the HTTP requests overhead and allows requesting (and repeat usage) through references.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check the visual spacing of elements is not too cramped.</li>
									<li>Check the scroll length of the document does not exceed a stated length.</li>
									<li>Check the number of DOM nodes in the tree does not exceed a stated number.</li>
									<li>Check the number of HTTP requests does not exceed a stated number.</li>
									<li>Check if optimizing will be beneficial, if so, implement a solution.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD01-2: Calculate the Energy Intensity of Technologies for Existing Projects -->
						<details>
							<summary>WD01-2: Calculate the Energy Intensity of Technologies for Existing Projects</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to distinguish different technologies and the role they play, identifying which are the most resource-intensive and providing either a mechanism to reduce the intensity of heavy payloads or to load-balance the most demanding aspects of these features. It's important to consider that in terms of rendering, data transfer is not the only consideration.</p>
								<p>In terms of machine testability, calculating the percentage of HTML, CSS, JavaScript, images, media, etc, isn't enough. It's critical to weigh and calculate the energy requirements of each aspect of those languages on an atomic level to identify potential rendering issues from the browser as these will impact upon hardware (CPU, GPU, <abbr title="Random Access Memory">RAM</abbr>, and other variables) having ESG implications.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Primary <a href="https://websitesustainability.com/#content">research exists</a> to calculate the energy intensity of front-end specifications and this could guide your ability to identify the energy intensity of components beyond the amount of data transferred.</li>
									<li><a href="https://www.thegreenwebfoundation.org/co2-js/">Co2.js</a> is a JavaScript library that can help developers estimate the relative carbon emissions of their applications, websites, and software using several variables (though it won't account for everything).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check the energy intensity of the HTML elements and attributes used.</li>
									<li>Check the energy intensity of CSS At-Rules, Selectors, Pseudo's, Properties, and Values.</li>
									<li>Check the energy intensity of JavaScript, DOM, <abbr title="Cascading StyleSheets Object Model">CSSOM</abbr>, and API usage.</li>
									<li>Check the energy intensity of image and media usage.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD02-1: Minify Your Front-End Code if It Is Public Facing -->
						<details>
							<summary>WD02-1: Minify Your Front-End Code if It Is Public Facing</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism in which your production-ready source code can have unnecessary data such as code comments, whitespace data, and machine-detectable redundancy removed to deliver the smallest file payload possible to the visitor. This will improve both the speed of your site and lower screen usage (wait) time.</p>
								<p>In terms of machine testability, the functions of a minification tool can be replicated for the languages HTML, CSS, and JavaScript using scripts and these can identify improvements to be made. Function names can be uglified (shortened to the smallest value) to reduce the size of the payload further and reporting tools can make recommendations based upon feedback.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Projects that are both public-facing but also allow for others to contribute to development should allow for <a href="https://unminify.com/">un-minification</a>. Developer tooling often contains features or extensions to restore code to a readable state.</li>
									<li><a href="https://mithril.js.org/">Mithril</a> is an example of a JavaScript framework that uses minification to great effect. It's small to start with but by offering both developer and minified versions on its GitHub repository you get the best of both worlds.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if your HTML, CSS, and JavaScript can be minified.</li>
									<li>Check if JavaScript can gain size reductions through uglify processes.</li>
									<li>Check if the code is on a non-production public-facing website.</li>
									<li>Check if obfuscation exists, if not minify the source code.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD03-1: Implement Code-Splitting Where Appropriate To Reduce Payloads -->
						<details>
							<summary>WD03-1: Implement Code-Splitting Where Appropriate To Reduce Payloads</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism where modularization can occur to reduce the overall payload of applications, libraries, and frameworks for the Web. By using code-splitting and modules where isolating code can take place (machine-testability can detect this), large components can be successfully broken down into pieces that will be delivered as required.</p>
								<p>This technique is most useful when dealing with significant-sized or complex pieces of production code that may not be required to be delivered in a single volume. If functionality will be used on-demand (for example), the payload to activate and run the functionality could be fetched and run when it is needed instead of the entire applications library being gathered upon page load.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>MDN <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules">provides a detailed guide</a> to JavaScript modules that are contained within many frameworks today to split them into separate component-based libraries to be called only when they are required by the visitor.</li>
									<li>Separating CSS into stylesheets based on arguments such as <a href="https://polypane.app/blog/the-complete-guide-to-css-media-queries/">media or preference queries</a> (or in rarer instances using imports), allows for large stylistic libraries to be broken down and requested only if its necessary.</li>
									<li><a href="https://alpinejs.dev/">Alpine</a> is a JavaScript framework that uses modules effectively to import the features it requires, and as such, remains fast and lightweight compared to competing frameworks that load everything in one go.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check the size of packages to determine the benefit of code-splitting.</li>
									<li>Check if CSS would benefit from being split into separate stylesheets based on queries.</li>
									<li>Check if JavaScript can be modularized and imported when required.</li>
									<li>Check if obfuscation exists, if not code-split the source code.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD04-1: Eliminate Redundant Code Through Coverage or Tree Shaking -->
						<details>
							<summary>WD04-1: Eliminate Redundant Code Through Coverage or Tree Shaking</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to eliminate redundancy within an application or website that may have been either introduced previously or through error. By using browser development tooling such as DevTools coverage or techniques like tree shaking any code which is no longer associated with functionality can be identified as potentially fit for removal (always verify this is accurate).</p>
								<p>For machine testability, redundant (orphaned / unused) code can be identified by its lack of association with existing components within the web page or application. Consideration will also need to be given to components that may be generated mid or post-render in addition to styles that only trigger when a certain state occurs (such as through hover or the target pseudo selector).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://web.dev/articles/reduce-javascript-payloads-with-tree-shaking">This article by Jeremy Wagner</a> showcases the importance of tree shaking within projects, including the history behind it and how it functions, in addition, it provides a few useful code examples.</li>
									<li>You can identify unused code within a project using Google Developer Tools in the <a href="https://developer.chrome.com/docs/devtools/coverage">Coverage Panel</a>. While there are a few gotchas (such as identifying inactive pseudo selectors), it's a useful way to weed CSS.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check CSS to determine if redundancy exists within your code.</li>
									<li>Check packages to determine if redundancy exists within JavaScript.</li>
									<li>Check if redundant code may be reintroduced, if not, remove it.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD05-1: Conform to WCAG as a Baseline Level of Acceptable Accessibility -->
						<details>
							<summary>WD05-1: Conform to WCAG as a Baseline Level of Acceptable Accessibility</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for ensuring that a website meets a baseline level of accessibility compliance as recommended by the Web Content Accessibility Guidelines (WCAG). Having an inclusive product or service is at this point (in most places) a legal requirement and meets ESG (social) factors in addition, so it becomes a sustainability compliance target.</p>
								<p>Machine testability for accessibility exists on some level already through automated testing tools and this can potentially be integrated into a custom white-label product (or created from scratch) if required, by identifying the criteria set out in WCAG A-AAA and attempting to seek machine testability with the guidelines and success criteria (as you are doing with the WSGs).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Testing your product or service in several screen readers such as <a href="https://www.nvaccess.org/">NV Access</a> will help establish that individuals with vision impairments can more easily navigate around your content.</li>
									<li>Tooling such as <a href="https://webhint.io/">WebHint</a>, <a href="https://github.com/dequelabs/axe-core">Axe Core</a>, or <a href="https://wave.webaim.org/">WAVE</a> helps product creators identify certain accessibility issues that can occur within a website or application though they can only test what can be identified by a machine.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if the application or website meets a specified level of WCAG.</li>
									<li>Check beyond WCAG for additional inclusive design requirements.</li>
									<li>Check for compatibility with several different accessibility tools.</li>
									<li>Check if an accessibility statement exists and testing is included.</li>
									<li>Check if additional legal compliance requirements are being met.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD05-2: Provide ARIA Enrichment to HTML Only if Deemed Necessary -->
						<details>
							<summary>WD05-2: Provide <abbr title="Accessible Rich Internet Applications">ARIA</abbr> Enrichment to HTML Only if Deemed Necessary</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism to identify firstly if ARIA support is required for assistance devices and secondly, if it is required, to implement that support if and only if it will enhance the solution to aid the accessibility of the product or service being given. The use of ARIA for code enrichment should only be utilized if no alternative can be utilized.</p>
								<p>For machine testability, the use of heuristics to examine the code structure and if certain components require additional semantic clarification is technically possible. Certain HTML elements for example will have built-in semantic value and require no contextual clarifications while custom elements or components of complexity (such as those used in applications) may require enrichment.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.aditus.io/aria/aria-current/">This document from Aditus</a> provides some general examples of ARIA in action showcasing how others have implemented it successfully within their projects (and naturally where it could be appropriate for use).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if the application requires ARIA before implementation.</li>
									<li>Check if the ARIA use is appropriate and correctly marked up.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD06-3: Write Code for Performance Removing Duplication -->
						<details>
							<summary>WD06-3: Write Code for Performance Removing Duplication</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism within projects to eliminate redundancy within your coding methodology. There will be occasions where the same solution is required for multiple events and in preference to repeating the code to achieve the same effect, referencing the code to perform on each occasion is more optimal as it reduces duplication and repetition.</p>
								<p>In terms of machine testability, identifying a coding methodology within languages like CSS can be easily accomplished by the way naming schemes are formed (such as the <abbr title="Block Element Modifier">BEM</abbr> pattern). In terms of repeat coding, using <abbr title="Don't Repeat Yourself">DRY</abbr>, repeated CSS property and value pairs (or in JavaScript, code that repeats the same action) can be identified and flagged for rearrangement.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>BEM (<a href="https://getbem.com/">Block Element Modifier</a>) is a methodology that is commonly used within websites to assist with creating reusable components and patterns, using easier-to-name schemes within front-end development.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for a recognized naming methodology or pattern in CSS.</li>
									<li>Check for the absence of repeating code (DRY) within CSS.</li>
									<li>Check for duplicate functionality or names within your JavaScript.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD07-1: Determine and Decision Make Upon Third-Party Impacts -->
						<details>
							<summary>WD07-1: Determine and Decision Make Upon Third-Party Impacts</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to first identify any third-party components within a website or application, then analyze that feature as if it were a first-party product or service (against the WSGs) for sustainability. If the product or service is determined to be highly impactful in a negative way, the third-party should be replaced or removed; otherwise, it can be optimized, or stay as-is.</p>
								<p>As third-party components are hosted externally, machine testing these elements should involve isolating these components and testing them as separate from the product or service. This can be factored into any decision-making regarding inclusion as highly performant and sustainable third-party materials will ultimately be low impact (and the opposite is true for others).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://wiki.openstreetmap.org/wiki/Using_OpenStreetMap">OpenStreetMap</a> allows for <a href="https://medium.com/@nargessmi87/how-to-embede-open-street-map-in-a-webpage-like-google-maps-8968fdad7fe4">embedding of their map data</a> in websites and applications which can be useful for providing directions to physical locations, but it could also drain data and rendering resources.</li>
									<li>A carousel with multiple resources (potentially being sourced from a third-party photo library) could be pretty to look at, but the combination of both animation and rendering may affect your visitor's battery.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if any third-party components exist within the page or application.</li>
									<li>Check that component against the WSGs for its sustainability compliance.</li>
									<li>Check if high-impact third-party components offer self-hosted alternatives.</li>
									<li>Check that self-hosted alternatives are used if provided.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD07-2: Provide an Import on Interaction Delay for Third-Party Resources -->
						<details>
							<summary>WD07-2: Provide an Import on Interaction Delay for Third-Party Resources</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism to delay third-party content from loading to the screen until the visitor has requested it. Because third-party content is sourced from outside the origin domain, the sustainability impacts of the third-party code are outside of the control of a project, and thus click-to-load delay screens using the import-on-interaction pattern is critical.</p>
								<p>The pattern used to either switch in the third-party content or load it on-demand can be machine-identified and if common third-party library resources are identified as loading (or leaking) upon a visit, this can and should be flagged up as a failure of the success criteria in functioning upon the visitor request (as such external requests should be within the visitor control).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.bbc.co.uk/news/entertainment-arts-68590845">BBC News</a> uses a cloaking mechanism to prevent third-party content of social media sites from loading unless requested by the visitor to reduce the impact on their devices (if this fails to work, a source link is offered).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if any third-party components exist within the page or application.</li>
									<li>Check that it exists behind a click-to-load delay screen (that visitors must request).</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD07-3: Identify Lightweight Alternatives to Unsustainable Third-Party Resources -->
						<details>
							<summary>WD07-3: Identify Lightweight Alternatives to Unsustainable Third-Party Resources</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to reduce the overhead of libraries and frameworks which may be used by the product or service but could be offered through lighter or less production-heavy alternatives. This will have significant sustainability benefits as replacing a heavyweight framework where only a small proportion of features are used with one that is potentially 1/5th of the size could not only improve performance but reduce the rendering load.</p>
								<p>This will require testability tooling to have both a library of existing frameworks and libraries - including smaller single-purpose ones (with the functionality they contain) and the ability to identify within code the feature set that is being utilized by a product or service. Through isolating in-use capabilities, better recommendations can be made which could reduce the project payload.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://youmightnotneedjquery.com/">You Might Not Need jQuery</a> provides information about potential replacements for the longstanding JavaScript framework that could be more performant and lightweight while offering the same functionality.</li>
									<li><a href="https://github.com/camsong/You-Dont-Need-jQuery">You (Might) Don't Need jQuery</a> showcases a series of examples of how pre-existing jQuery functionality can now be replaced with native functionality and as such, the framework could be eliminated.</li>
									<li><a href="http://microjs.com/#">MicroJS</a> is a list of tiny JavaScript frameworks that serve a single purpose and if you utilize a single large framework for this very reason, could be swapped out to reduce the ecological impact of your work.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if CSS libraries could be replaced with smaller alternatives or custom code.</li>
									<li>Check if JavaScript frameworks could be replaced with smaller alternatives or native code.</li>
									<li>If replacements can be made, then replacements should be introduced.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD07-4: Ensure That Content Is Delivered Through the Most Sustainable Pathway -->
						<details>
							<summary>WD07-4: Ensure That Content Is Delivered Through the Most Sustainable Pathway</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to identify the location of website content and determine the most suitable pathway for it to be consumed sustainably. With the rise in content being hosted on third-party blogging platforms, there is a risk of significant content loss if the platform disappears and therefore a need for self-hosting exists (especially to maintain control of sustainability impacts).</p>
								<p>For machine testability, identifying the source of the content is a key priority, then determining the impact of any third-party (the risk of content loss along with any sustainability impacts through WSG testing). Finally, this should be weighed up against the impact of self-hosting (and any potential negative consequences such as content moderation requirements that may occur).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://medium.com/">Medium</a> is a popular content hosting platform yet while it does offer a reasonably readable interface, it may not be as sustainable as providing the content within your own website or application in a dedicated blog.</li>
									<li>Social media posts are contained within your account on that network (in some social networks are only visible to members or even users of a mobile application) and will have the sustainability issues of that provider.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if the level of content being published is regular.</li>
									<li>Check if features such as comments are a requirement (if so, can moderation be offered).</li>
									<li>Check if the website already has an audience to give content visibility.</li>
									<li>If so, check that the content is self-hosted on the first-party domain.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD07-5: Create Custom Clickable Icons and Widgets for Third-Party Services -->
						<details>
							<summary>WD07-5: Create Custom Clickable Icons and Widgets for Third-Party Services</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for interacting with third-party products and services through your own project without having to rely on a third-party solution that will inevitably have tied sustainability impacts that are bound to a third-party service. Creating these custom repeatable use objects can have either a single function use, or can serve multiple functions.</p>
								<p>Identification of third-party solutions can be found through heuristics of source code and recommendations can be made to produce custom first-party solutions for sustainably impactful services. Additionally, custom solutions can often be identified based on either the goal they aim to achieve or the label they are given within HTML ID or class names that can be identified.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>There are <a href="https://freefrontend.com/css-social-media-icons/">many examples</a> of custom social media icons <a href="https://codepen.io/sanketbodke/pen/LYymbRq">embedding</a> out there, and there are also plenty of <a href="https://simpleicons.org/">free libraries</a> out there you can choose between to avoid relying on the default offerings by providers.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the product or service has accounts with different service providers.</li>
									<li>Check that a custom solution is either in link form, icon form, or looks similar to the provider's native implementation.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD07-6: Provide the Ability To Identify and Choose Third-Party Components To Load -->
						<details>
							<summary>WD07-6: Provide the Ability To Identify and Choose Third-Party Components To Load</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide visitors with the optimum level of control over sustainability impacts by not just allowing them to identify and load third-party controls upon click but to also control third-party services, libraries, and tooling used by the product or service (even at load) via a preference panel where individual third-parties (which may be impactful) can be refused access.</p>
								<p>This mechanism if using a commonly accepted scheme could be detected by a machine. If the preference is presented upon load and not set by default and if the visitor has the option of selecting individual services (one at a time), accepting all, and denying all, then it can be deemed that the functionality is working as expected (as long as third-party services obey that scheme).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Cookie banners are a classic example of personalization from the point of the page load and they can dictate the functionality of a website or application based on the choices made <a href="https://www.optimizely.com/">as shown in this example</a>.</li>
									<li>Being able to log into to a product allows customers to trigger decisions regarding their experience. <a href="https://music.apple.com/">Apple Music</a> (for example) uses the details of the visitor to make decisions based on their prior browsing habits.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that information is provided to indicate upon load to indicate preferences.</li>
									<li>Check that the option to allow all, deny all, and select between providers is offered.</li>
									<li>Check that information is provided identifying providers and describing the options carefully.</li>
									<li>Check that preferences are remembered when navigating during the session.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD08-1: Validate Source Code for Semantic Accuracy -->
						<details>
							<summary>WD08-1: Validate Source Code for Semantic Accuracy</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that HTML meets the criteria for POSH (Plain Old Semantic HTML). This requires using the correct element for the correct purpose and avoiding common syntax mistakes that could be easily correctable. In terms of sustainability, it defines the importance of having code that remains as likely to stay functional in the future as possible.</p>
								<p>For machine testability, examining code for correct element use is a primary step but other features found in validation services such as ensuring elements are closed correctly, that HTML entities are correctly marked up, etc, are of equal importance to avoid rare issues that might occur during the rendering process (if browsers accidentally choose to interpret data incorrectly).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The W3C provides markup validation services for <a href="https://validator.w3.org/">HTML</a> and <a href="https://jigsaw.w3.org/css-validator/">CSS</a>, <a href="https://jsonlint.com/">JSON</a>, as well as <a href="https://validator.w3.org/feed/">feeds</a> to identify potential issues with the code. These tools can work with direct input as well as files and direct input.</li>
									<li>Linting tools can check (and be configured) to help you find and resolve common errors either while you code or during an auditing process. There are linting tools available for languages like <a href="https://markuplint.dev/">HTML</a>, <a href="https://stylelint.io/">CSS</a>, <a href="https://eslint.org/">JavaScript</a>.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if the HTML, CSS, and other source code contains resolvable errors.</li>
									<li>Check that any errors have been successfully linted and corrected.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD08-2: Eliminate Optional Code To Reduce the Rendering Impact -->
						<details>
							<summary>WD08-2: Eliminate Optional Code To Reduce the Rendering Impact</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for eliminating further redundancy from source code which may not be strictly required for semantic reasons but can help reduce the amount of data being transferred and thereby improve web performance. This can be done by removing any optional code from a document that will not affect the rendering of the page.</p>
								<p>This technique is most useful when subscribing to performance budgets and attempting to reach the smallest file size possible is of critical importance to reach ESG targets. Such optional code removal can be identified by machine and recommendations for where optimization can occur can be provided but there may be occasions (as with minification) in non-production to retain the data.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://meiert.com/en/blog/optional-html/">This article by Jens Oliver Meiert</a> provides details about some of the optional HTML elements you may wish to eliminate to reduce the amount of data being transferred to visitors during a page view session.</li>
									<li><a href="https://browserdefaultstyles.com/">Browser Default Styles</a> provides information about the CSS that a web browser will render to the visitor as a matter of course when an HTML element is created (therefore you don't need to repeat the statements).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that optional HTML elements that are unnecessary for rendering are removed.</li>
									<li>Check that browser default styles are not repeated in the stylesheets.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD08-3: Replace Non-Standard Code With Suitable Alternative Syntax -->
						<details>
							<summary>WD08-3: Replace Non-Standard Code With Suitable Alternative Syntax</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to identify and eliminate any non-standard coding practices including but not limited to proprietary additions included by web browsers to test new functionality before potentially including it fully within the web browser (this isn't so common today but remnants still exist). As older code is often not as highly optimized for performance, it can take longer to render and thrash hardware causing higher emissions so is worth resolving.</p>
								<p>For machine testability, lists of non-standard syntax are available within common specifications which can be used to identify within source code. In addition, browser-specific code can be identified by its prefix or on lists of techniques and hacks to resolve browser bugs. If replacements for these techniques can be offered, provide them, otherwise recommend removal from your code.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>In the past, it was necessary to provide specific coding techniques (known as hacks) to ensure web browser compatibility. <a href="http://browserhacks.com/">Browser Hacks</a>, lists the various patterns used that could be solutions fit for removal.</li>
									<li>When testing new features, browsers had a habit of <a href="https://shouldiprefix.com/">prefixing their code</a> in the past behind flags to avoid breaking existing code. Lists of such prefixes can be found online as well as archaic proprietary HTML and CSS.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that archaic proprietary specification additions are not included within the code.</li>
									<li>Check that browser prefixes have been removed from CSS unless required for compatibility.</li>
									<li>Check that no browser hacks exist unless they are required for compatibility.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD09-1: Set Scripts To Load Either Asynchronously or Deferred -->
						<details>
							<summary>WD09-1: Set Scripts To Load Either Asynchronously or Deferred</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for JavaScript (and if possible StyleSheets) to be loaded asynchronously or deferred to avoid acting as render blocking events which can delay the loading of content. This will lessen the initial impact on visitors' hardware and thus can have ESG and web performance benefits which should be taken into account.</p>
								<p>This technique is most useful when it is applied to all materials which will run upon the page load. In terms of testing for this technique, scripts can be identified by the attribute being provided within the HTML code. If the attribute is not provided, guidance can be offered to question if this was intentional or machine testing could analyze the code to verify if an issue will occur.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.chartjs.org/docs/latest/samples/tooltip/content.html">Chart.js</a> is a library that allows you to easily produce complex charts within a website or application. It uses a combination of asynchronous and deferred loading to ensure the rendering doesn't block other content.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that all scripts are set to load with either the async or defer attributes unless necessary.</li>
									<li>Check if CSS (<a href="https://www.holisticseo.digital/pagespeed/async-css/">with the aid of JavaScript</a>) could benefit from asynchronous loading, and if so, do it.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD09-2: Provide Assets Required at Load With the Correct Delivery Route -->
						<details>
							<summary>WD09-2: Provide Assets Required at Load With the Correct Delivery Route</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for assets to be loaded at the correct time in the rendering process. With the ability to use preload, prefetch, and preconnect we can take resources such as web fonts and scripts that are necessary for the product or service to successfully be able to be displayed and ensure they are prioritized over other web assets.</p>
								<p>Identifying that the asset being chosen for this mechanism is correct, linked to correctly, and has the right mechanism in place is of the highest priority for machine testers to ensure that the rendering process is not interrupted. If a low-priority object is given high priority it could delay the website or application from reaching the visitor and increase screen time.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.mightybytes.com/">Mightybytes</a> uses DNS prefetching to ensure that fonts and JavaScript that are hosted on a third-party CDN service will be less likely to suffer render-blocking (as the host is readied before the content is requested).</li>
									<li><a href="https://www.wholegraindigital.com/">Wholegrain Digital</a> uses preloading on its web typography to avoid render blocking with several different weights being offered on the same typeface (all of which will be downloaded as the content is).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that preload, prefetch, and preconnect are used as appropriate in HTML documents.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD10-1: Provide Accurate Social Metadata and Microdata -->
						<details>
							<summary>WD10-1: Provide Accurate Social Metadata and Microdata</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for social networks and search engines to first identify your website or application and then to be able to showcase it successfully within their products and services. Because each social network and search engine has its own requirements, it will involve a combination of different metadata and semantic markup to achieve results.</p>
								<p>For machine testability, toolmakers will need to maintain a list of the most popular products and services with which they wish to maintain compatibility. From there they will need to work through their requirements to ensure that the patterns expected are included within pages (and that they match the expectations of the providers so that results will ensure visitor findability).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The <a href="https://small-tech.org">Small Tech Foundation</a> ensures that their content can be easily identified by third parties by providing metadata, open graph data, and microdata within the document header (that is easily machine-readable).</li>
									<li>Many social networks take advantage of the <a href="https://ogp.me/">OpenGraph Protocol</a> including <a href="https://developers.facebook.com/docs/sharing/webmasters">Facebook</a> and <a href="https://developer.twitter.com/en/docs/twitter-for-websites/cards/overview/markup">X (formally Twitter)</a> in the HTML head. <a href="https://joinmastodon.org/verification">Mastodon</a> uses the rel="me" attribute to identify websites with owners.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the necessary OpenGraph data for Facebook is included within HTML.</li>
									<li>Check that the necessary Twitter Card data is included within HTML for X.</li>
									<li>Check that the necessary Mastodon link containing the rel attribute exists.</li>
									<li>Check that other social networks have their criteria met or have links added.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD10-2: Provide a Robots File That Contains Relevant Indexing Data -->
						<details>
							<summary>WD10-2: Provide a Robots File That Contains Relevant Indexing Data</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism of maintaining findability within products and services for search engines but also to attempt to (successfully or otherwise) reduce the amount of traffic from bad actors or unethical / unsustainable products that may impact your wider projects and service-users. This will be produced using the robots.txt document.</p>
								<p>This technique requires that the robots.txt file be present within the base directory of a website and be formatted according to the commonly agreed upon Robots Exclusion Standard. For the Success Criteria, listing bad actors and unethical / unsustainable products is considered optional however if such a list can be maintained and adhered to, it's worthy of inclusion.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.google.com/robots.txt">Google has a robots.txt file</a> of their own that identifies to search engines what pages should be included within search results. Naturally, you don't want to copy this file exactly but it may serve as inspiration!</li>
									<li><a href="https://www.robotstxt.org/robotstxt.html">The Web Robots Pages website</a> is a resource dedicated to the robots exclusion standard and how it can be applied to websites including different examples and details about the robots file structure.</li>
									<li><a href="https://developers.google.com/search/docs/crawling-indexing/robots/robots_txt?hl=en">Google Search Central</a> has a document that provides working examples of the robots file and the properties you should consider including within it (plus examples and details of how they will function).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for the existence of a robots.txt within the base directory of a website or application.</li>
									<li>Check that the document is well formed and contains the correct property / value pairs.</li>
									<li>Check for a list of blacklisted bad actors and unsustainable products.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD10-3: Add Signposting Within the Page To Direct Visitors and Accessibility Aids -->
						<details>
							<summary>WD10-3: Add Signposting Within the Page To Direct Visitors and Accessibility Aids</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide mechanisms to assist the visitor with finding and navigating through content within the page or application. This can come in the form of links that allow you to bypass blocks of content, which is especially useful when large vocal areas of navigation or other content exist. It could also be in the form of keyboard shortcuts that activate certain features within a complex application rather than having to click multiple steps.</p>
								<p>Machine testability for such features can identify events within JavaScript or features that use common patterns in code that are recognized as helpful signposting features. If such features are present then the success criteria can be marked as compliant but if none are found it could be an indicator, especially in complex websites or applications that such features are needed.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://webaim.org/techniques/skipnav/">WebAim has a great article</a> describing the details relating to skip links <a href="https://www.jimthatcher.com/skipnav.htm">as does Jim Thatcher</a>, both include plenty of useful visual examples and situations to work with when designing a custom solution of your own.</li>
									<li>Smashing Magazine published a <a href="https://www.smashingmagazine.com/2022/11/guide-keyboard-accessibility-html-css-part1/">two</a> <a href="https://www.smashingmagazine.com/2022/11/guide-keyboard-accessibility-javascript-part2/">part</a> guide to keyboard accessibility which included HTML, CSS, and JavaScript and covered not only skip links but also provided keyboard-based accessibility aids.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the project can be successfully navigated using the keyboard.</li>
									<li>Check that the tabindex order of the content makes logical, navigable sense.</li>
									<li>Check that skip links exist to guide accessibility tools through content.</li>
									<li>Check that keyboard shortcuts are well documented and work as expected.</li>
									<li>Check that signposting within pages are well described, and work as directed.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD11-1: Ensure That Form Inputs Correctly Match and Validate Content Expectations -->
						<details>
							<summary>WD11-1: Ensure That Form Inputs Correctly Match and Validate Content Expectations</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that input types correctly match the type of content being placed within them, that content types like passwords are handled in a way that visitors can easily reveal them, and that the patterns attribute is used correctly to help reduce errors during data entry. In doing so, friction encountered during form filling can be reduced as can erroneous submissions.</p>
								<p>Machine testability for this criteria will involve analyzing the components of forms to ensure they are well formed and that (for example) any regular expressions used in patterns will not produce an erroneous result. It is also important that functionality within forms perform well on mobile devices as well as desktop so consideration must be given to the choice of input for tasks.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://thegood.com/insights/form-design-examples/">This article from TheGood</a> showcases multiple examples of great form design not only from the point of the user-experience but also in the development to ensure that the ability to make mistakes is reduced.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the input type matches the expected content type.</li>
									<li>Check that the use of the pattern attribute does not prevent correct input.</li>
									<li>Check that regular expressions are correctly formed and do not equate errors.</li>
									<li>Check that password fields can be made visible to allow for recognition.</li>
									<li>Check that one input type will function well on mobile devices over another.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD11-2: Ensure That Form Elements Are Correctly Labeled -->
						<details>
							<summary>WD11-2: Ensure That Form Elements Are Correctly Labeled</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for accessibility tooling to be able to accurately describe the content of form features and to provide visual aids for visitors aiming to identify what information is required to be entered. This technique requires all interactive elements within the form to have an associated label to describe the purpose and / or role of the item.</p>
								<p>Labels should be presented directly beside the element in question to imply association and if multiple associations are required, a grouping element with a label can be provided. Machines should be able to identify the relationship between the label and the object through the syntax and if objects without labels exist, a failure statement can be flagged up.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://codepen.io/sushma-io/pen/zYbOREe">This CodePen example</a> clearly has all interactive elements within the form correctly labeled and additionally goes the extra step by using input types to help reduce the chances of errors occurring during data entry.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that all interactive form components are correctly labeled.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD11-3: Reduce Friction Within Data Entry With Manual Third-Party Content -->
						<details>
							<summary>WD11-3: Reduce Friction Within Data Entry With Manual Third-Party Content</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism in which visitors can easily take content from third-party sources and use it within your product or service. Techniques such as the ability to paste into forms or the ability to drag and drop can act as shortcuts to avoid retyping or recreating (using system resources) which may be energy-intensive or time-intensive for the visitor.</p>
								<p>Identifying mechanisms that may prevent the ability to import third-party content such as blocking pasting content or disabling the ability to drag and drop should be detected and flagged (unless a reason for this can be justified within the code). Mechanisms that aid the ability to import third-party content such as import or paste buttons should be actively encouraged.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>These CodePen examples of <a href="https://codepen.io/colorlib/pen/rxddKy">log in</a> and <a href="https://codepen.io/RajRajeshDn/pen/QWwypRy">registration</a> forms do not inhibit the visitor from pasting content from third-party sources which allows for fast data entry if the information is stored elsewhere.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the ability to paste content is uninhibited (no onpaste="return false;").</li>
									<li>Check that the ability to drag and drop third-party content can be achieved successfully.</li>
									<li>Check that import options are provided if the above two options are unavailable or fail.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD12-1: Ensure That the Required HTML Elements Are Included -->
						<details>
							<summary>WD12-1: Ensure That the Required HTML Elements Are Included</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that the minimum required features are present to render a website or application correctly. This includes but is not limited to a DocType and a series of HTML elements (at a bare minimum). The justification behind this is while a page can technically show without them it is considered bad practice and malformed HTML to not include such features.</p>
								<p>For machine testability, the ability to identify a DocType (and the version of HTML being rendered), plus ensuring that the necessary base HTML elements are present is script detectable. This can be done via the validation process, manually, or automated to ensure pages render correctly and avoid triggering quirks mode (that will affect the visual rendering of the website or application).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Courtney Thomas back in 2018 <a href="https://medium.com/@cortneythomas/laymans-coding-what-is-the-minimum-html-you-need-for-a-website-eda987b02622">created a great article</a> that showcased the minimum HTML that is required for any website or application (though <a href="https://htmlhead.dev/">as Josh Buchea notes</a>, the viewport meta tag should also be there).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the document includes a well-formed DocType.</li>
									<li>Check that the page or application includes the required HTML elements.</li>
									<li>Check that the page or application includes valid links to CSS and JavaScript assets (optional).</li>
									<li>Check that the HTML includes the viewport META element for handheld devices.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD12-2: Provide Relevant Metadata Using a Recognized Scheme -->
						<details>
							<summary>WD12-2: Provide Relevant Metadata Using a Recognized Scheme</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide the necessary metadata within the head of your website or application to ensure that search engines can index your content correctly. You can use several different mechanisms to achieve this as several different formatting schemes have been provided over the years and they have varying levels of support by different search providers.</p>
								<p>To enhance the findability of your content (which will reduce time being wasted by visitors trying to locate you), having a well-formatted series of metadata is critical. As such, testing should focus on determining whether basic meta tags are used or if another format is being used to serve data. Once detected, identify if the tags are recognized, if they aren't in common use or have been deprecated by a provider, it's worth requesting removal for the data savings.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The <abbr title="Web Hypertext Application Technology Working Group">WHATWG</abbr> not only has within the <a href="https://html.spec.whatwg.org/multipage/semantics.html">HTML specification</a> a list of recognized elements that can provide contextual information about the page, but it also has a wiki that lists <a href="https://wiki.whatwg.org/wiki/MetaExtensions">proprietary META tags</a>.</li>
									<li>The <a href="https://www.dublincore.org/specifications/dublin-core/dcmi-terms/">Dublin Core Metadata Initiative</a> was an attempt to standardize meta tags with a set labeling scheme. It's supported by the majority of search engines and could be used (as is or in <abbr title="Resource Description Framework in Attributes">RDFa</abbr>) instead of other formats.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the HTML document contains a description META element of <a href="https://moz.com/learn/seo/meta-description">between 50 and 150 characters</a>.</li>
									<li>Check that the HTML document contains additional metadata from a recognized scheme.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD12-3: Ensure Content Is Structured Using Microdata -->
						<details>
							<summary>WD12-3: Ensure Content Is Structured Using Microdata</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide mechanisms for search engines and social networks (and sometimes even visitors and web browsers!) to take context-rich content from your website or application and re-use it for the benefit of your product or service elsewhere. Structuring your content successfully can take place (like metadata) using one of several formats.</p>
								<p>Because microdata uses hooks that attach to existing HTML to make it easy to identify (for search engines and third-parties), this will also make it easy to identify for machine testability. Using a pattern library of these various structural features you can not only show visitors how content could be used but using heuristics identify other content that might benefit from it.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://schema.org/">Schema</a> is a database of common patterns that have been formed using microdata. It's a huge library and could be potentially helpful in describing certain components in a way that search engines can recognize.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that content is correctly marked up using microdata, microformats, etc.</li>
									<li>Check for external RDFa assets that may contain rich metadata.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD13-1: Ensure CSS Preference Media Queries Are Correctly Applied -->
						<details>
							<summary>WD13-1: Ensure CSS Preference Media Queries Are Correctly Applied</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide mechanisms through CSS that adhere to the visitor's preferences regarding how they may choose to browse a website or application. While some queries that exist in the language will hold little sustainability value, others could have ESG benefits through accessibility (social factors), or environmental (reducing hardware or data usage).</p>
								<p>Each of the preference queries can be machine-identified through scripts and therefore can be tested against firstly for browser support, and secondly that the project provides some kind of environmental consequence for using the query that will benefit the visitor and / or the ecosystem. The value of such queries being applied could be measured by triggering or emulating them.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://hidde.blog/">Hidde de Vries</a> has a dark mode toggle that using a mixture of CSS preference queries and JavaScript allows dark or light mode to either be user-triggered or run at the default (it's non-invasively implemented).</li>
									<li><a href="https://webkit.org/blog-files/prefers-reduced-motion/prm.htm">These examples</a> provided by the Webkit team showcase how reduced motion (when enabled) can prevent excess movement. Though a toggle (<a href="https://codepen.io/smashingmag/pen/porEQLB">such as this by Michelle Barker</a>) could provide <a href="https://www.smashingmagazine.com/2021/10/respecting-users-motion-preferences/">added use-cases</a>.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for preference queries and that the effect they produce is beneficial.</li>
									<li>Check for manual override toggles or preferences within the page.</li>
									<li>Check for alternative styles if paged media or scripting is disabled.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD14-1: Test Against Network Speeds and Visual Resolution Breakpoints -->
						<details>
							<summary>WD14-1: Test Against Network Speeds and Visual Resolution Breakpoints</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that your product or service can be classified as mobile-first and responsively designed to hopefully assure the widest remit of device types, and at least some degree of visual compatibility with your website or application. While there are many ways to approach this task, this technique is focused on connection speeds and the potential window size.</p>
								<p>Because connection speeds can vary based on a whole range of factors (and cannot be aligned with averages due to location, mobile vs home, connection quality, etc), multiple speed ranges should be machine tested against. The same can be said for window sizes as while resolutions are common to certain devices, browsers can be resized, and unusual device types do also exist therefore CSS fluid scaling and visual breakpoints should be utilized.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://www.webpagetest.org/">WebPageTest</a> allows you to check how a product or service will perform at different speeds (including custom profiles you set up). Running such tests can identify if a product or service takes too long to load.</li>
									<li>Browser developer tools can test a website at various dimensions (on desktop) and by manually resizing the browser window with the developer tools open (and rulers toggled in Firefox), you can identify breakpoints where the design of the site requires code solutions.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the website or application performs well on a variety of network speeds.</li>
									<li>Check that the product or service visually doesn't break when resized at multiple window sizes.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD14-2: Provide Progressive Enhancement Feature Testing Within Projects -->
						<details>
							<summary>WD14-2: Provide Progressive Enhancement Feature Testing Within Projects</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for providing features within your product or service only if they are supported and if not, providing alternatives. This can be done using feature detection and progressive enhancement which should be used as a priority over graceful degradation (as it is better to add useful extras rather than patch-critical - but broken content).</p>
								<p>Machine testability for feature testing should identify any code within the product or service that relies upon newer functionality lacking a level of web browser support (either in competing products or older versions), testing should occur and errors should be handled. Furthermore, if technologies are not supported, the fallback mechanism should allow a basic project to run.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Jeremy Keith's Website (<a href="https://adactio.com/">Adactio</a>) is a great example of progressive enhancement in action. It works if JavaScript, CSS, or even images are disabled (though naturally, the visuals can suffer as a result!).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the website or application can function if JavaScript is disabled.</li>
									<li>Check that the page is still functional if an older browser version with older JavaScript and CSS version is used.</li>
									<li>Check that the product or service is still functional if CSS is disabled.</li>
									<li>Check that the product or service is still functional if images or media are disabled.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>Expectation of the above is dependent on the task but should aim to be true unless necessary.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD14-3: Configure Your Project Around Carbon-Aware Situations -->
						<details>
							<summary>WD14-3: Configure Your Project Around Carbon-Aware Situations</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for identifying when the project might be at its most resource or energy-intensive (either at the consumer level or the system level - or both), and then decision make to delay or alter when a heavy script or operation occurs to perform it when there are fewer visitors or when the user is causing less hardware intensive activity.</p>
								<p>For machine testability, this could be particularly tricky to implement as it will rely on data to which the project owner will need to gain access such as when visitor numbers are at their lowest (or when the task can be achieved at its quickest). This may require internal access, but if granted the use of such data could allow for redesigning the site to perform better during busy periods.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://app.electricitymaps.com/map?solar=false&remote=true&wind=false">Electricity Maps</a> provides an application that could be utilized to help make decisions as to where data is being served (based upon the intensity and level of renewables being offered in particular regions).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if operations can be built to function using carbon-aware technologies or resources.</li>
									<li>Check if operations can be processed or shifted to occur during less carbon-intensive periods.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD14-4: Provide Low-Impact, Possibly Delayed Methods of Interaction -->
						<details>
							<summary>WD14-4: Provide Low-Impact, Possibly Delayed Methods of Interaction</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for interacting with a website or application using more usual methods, but methods that often will have a reduced overall impact (such as having a reduced energy requirement). These indirect methods such as syndication feeds or the browser reader view can even eliminate the heavy impact of rendering that can affect hardware.</p>
								<p>This technique is most useful when it can be easily recognized by visitors and can be used instead of having to visit the main website or application. In terms of machine testability, if these low-impact techniques use a common pattern and that pattern can be easily identified within the source code then naturally it can be identified as such and can be marked as meeting the criteria.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Quick Response (<abbr title="Quick Response">QR</abbr>) codes are a great example of objects that can be included not only online but offline in branding to trigger both links and in-app actions with only the impact of rendering the object (or printing it).</li>
									<li>Smartwatches may have some Internet connectivity. Due to the small screen size, they will have a low energy output but also a small battery so having a low-fidelity version of a website can be really useful.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for low-impact interaction methods such as QR codes, smartwatch layouts, or voice assistant tooling.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD15-1: Optimize a Codebase Through Rewriting for Performance -->
						<details>
							<summary>WD15-1: Optimize a Codebase Through Rewriting for Performance</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to improve the quality of JavaScript code by examining the contents and identifying any issues that could be deemed a matter of sustainability which could trigger a large load upon hardware resources (and thus put a strain on battery charge cycles). In addition to this, matters of accessibility and performance with such code can be considered.</p>
								<p>To meet the success criteria, rewriting for performance should only be done if the act does not cost more in effort (and creator impact) than it gains in impact. For machine testability, it's critical that such actions within scripting use tools at their disposal (libraries, patterns, even <abbr title="Artificial Intelligence">AI</abbr>) to heuristically identify any issues that may require resolution within the project's source code.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Solid.js author Ryan Carniato created <a href="https://javascript.plainenglish.io/how-we-wrote-the-fastest-javascript-ui-frameworks-a96f2636431e">this thoughtful post</a> in 2019 about how they went about integrating web performance in their framework-building processes. It is based on a widely recognized JavaScript study.</li>
									<li>The team at Astro <a href="https://astro.build/blog/2023-web-framework-performance-report/">used open data to examine</a> the performance ratings of various competing JavaScript frameworks to identify the differences between physical and real-world metrics (there are lots of useful charts).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that existing code has been rewritten to be less process intensive, etc.</li>
									<li>Check that any existing tooling is considered sustainable and / or performant.</li>
									<li>Check if JavaScript frameworks can be replaced with others that are more performant.</li>
									<li>If frameworks can be replaced, check that they are replaced.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD16-1: Ensure All Vulnerabilities Are Removed and Code Is Linted -->
						<details>
							<summary>WD16-1: Ensure All Vulnerabilities Are Removed and Code Is Linted</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to scan the website or application's code for issues that may otherwise potentially leave a product or service vulnerable to exploitation. This will not only include first-party code that is created by the project owners but third-party tooling imported. Any third-party library or framework found to contain harmful code should be removed before production.</p>
								<p>Because this can occur at both the client-side and server-side internal access may be required if server-side scanning is wished to be included within machine testability, however within the scope of the success criteria, if internal access is not available or permitted, testing the code using known methods and scanning client-side code for harmful techniques should help with passing.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>RayGun <a href="https://raygun.com/blog/js-security-vulnerabilities-best-practices/">provides a great article</a> about vulnerabilities and best practices when working with JavaScript. Some of the things mentioned are covered within the WSGs in other sections, all others can be followed here.</li>
									<li><a href="https://snyk.io/">Snyk</a> is one of the most well-known providersof data regarding code vulnerabilities. They can be integrated within existing tooling or you can browse their <a href="https://security.snyk.io/">database of known security issues</a> to be aware of.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check the product or service for vulnerabilities within your code, ensuring they are resolved.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD17-1: Identify and Remove Unused Packages and Dependencies -->
						<details>
							<summary>WD17-1: Identify and Remove Unused Packages and Dependencies</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for identifying if a library or framework is currently in use and if not, remove the said tooling and its unused dependencies from the production code. This will help reduce the ESG burden of the website as less bloat will reach the visitor which can have a large impact if they are on a low-powered device or a restricted data plan.</p>
								<p>For machine testability, internal access will be required to determine if web developers or creators will require specific tooling within a project. If internal access is given, the package.json file is an ideal place to locate the packages being requested and these can be compared against the public-facing website to identify redundancy in the toolchain process.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>An application that removes functionality due to poor uptake no longer requires certain packages to contain scripts that were dedicated to running that function alone. Such dependencies have become redundant.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if a package.json has been submitted for identifying packages.</li>
									<li>If so, use that. Otherwise, check the source code for potential orphan references.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD17-2: Implement Modularized Frameworks and Libraries -->
						<details>
							<summary>WD17-2: Implement Modularized Frameworks and Libraries</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for determining how much of a library of framework you require for your website or application to function, and then requesting just that modularized segment to reduce the overall payload and load on the visitor's hardware during rendering. This is especially critical for third-party scripting but is also useful for CSS.</p>
								<p>Machine testability should attempt to identify when third-party libraries are present within a codebase and if that framework or library supports the ability to load a lightweight or modular version of its features (thereby only loading what you require, when you require it), ensure that the project in question does so rather than loading an un-optimal "fully-loaded" version of the project.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://bundlephobia.com/">Bundlephobia</a> and <a href="https://pkg-size.dev/">pkg-size</a> allow you to find the true size of a package on NPM by calculating not just the size of the item you wish to install but all of the dependencies the item requires to function.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check the package size to determine at what size breaking into modular components should occur.</li>
									<li>Check the function sizes to identify if refactoring to smaller functions should also occur.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD17-3: Ensure That Dependencies Are Verified As Up-to-Date -->
						<details>
							<summary>WD17-3: Ensure That Dependencies Are Verified As Up-to-Date</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that the deliverables are current and up-to-date, thereby providing any necessary security patches or bug fixes that are required to remain operational. This is especially true when a website or application is dependent on third-party libraries or frameworks and has a complex toolchain. As such, verifying the maintenance status of work is critical.</p>
								<p>To machine test or verify the dependency chain of a project, the source code of a project should identify (by filename or URL) the project and version. If during the tree shaking or production process all notifications of what third-party code has been used have been removed, internal access will be required to access the package.json (except heuristic fingerprinting of packages).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>As you would expect, the <a href="https://jquery.com/">jQuery project website</a> uses the latest version of the jQuery framework. Because it is a regularly maintained project and can afford rapid update cycles, it stays current and up-to-date.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if a package.json has been submitted for identifying packages.</li>
									<li>If so, use that. Otherwise, check the source code for package version data.</li>
									<li>Check that all packages are at least non-breaking (minor) current if not major release current releases.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD18-1: Provide the Expected Website Assets in Your Base Directory -->
						<details>
							<summary>WD18-1: Provide the Expected Website Assets in Your Base Directory</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that the non-HTML files that are expected to be located within the base directory of a website can firstly be found and secondly are correctly formatted (using the right syntax) and match the expectations of the product or service that requires them to benefit the visitor with a better user-experience, increased accessibility, and sustainability.</p>
								<p>For machine testability, tooling should aim to identify that the listed files are provided (if not flag these justifying the need for their inclusion). If they are included they should be examined to ensure they are semantically correct, especially if they are formed using a strict language such as XML. If they fail to validate correctly errors should constitute a failure to meet the success criteria.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>Amazon has a highly recognizable brand and they <a href="https://www.amazon.com/favicon.ico">provide a favicon</a> in the base of their website so that when people visit them, their icon will show correctly in the top left of the tab or window (browser dependent).</li>
									<li>Developer tool Can I Use <a href="https://caniuse.com/opensearch.xml">provide an opensearch.xml file</a> in the base of their website so that if people visit their project, visitors can rapidly search the website in the future using a keyword and tab combination.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check the base directory for a favicon in 16&times;16, 32&times;32, and 48&times;48 format.</li>
									<li>Check the base directory for a well-formed robots.txt document.</li>
									<li>Check the base directory for a well-formed opensearch.xml and sitemap.xml file.</li>
									<li>Check the base directory for a well-formed site.webmanifest document.</li>
									<li>Check that the links contained within these documents don't contain errors.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD19-1: Provide Useful Plaintext Website Assets in the Expected Locations -->
						<details>
							<summary>WD19-1: Provide Useful Plaintext Website Assets in the Expected Locations</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for adding useful contextual information to a website or application within recognized locations in plaintext format (so that it doesn't impact the rest of the product or service). These standardized formats each have a defined beneficial purpose and are considered to be low-impact (sustainably speaking) so are safe to include.</p>
								<p>This technique is most useful when the assets are formatted as per their specification for purposes of readability, it is how individuals and machines will be expected to understand them. For machine testability, using heuristics to scan for recognized features within the text should help you identify the instructions or any features of note that could be weighed in calculations.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://wordpress.com/ads.txt">WordPress has an ads.txt file</a> at the base of their website, that contains details of the advertisers they work with (and tries to increase transparency by revealing where impressions are purchased and resold).</li>
									<li>Web Developer Sarah Tamsin has a <a href="https://sarahtamsin.com/humans.txt">fun example of a humans.txt file</a> that provides some witty content and a few basic details about her (plus an ASCII image that makes for a nice easter egg bonus feature).</li>
									<li>The security.txt specification writers have <a href="https://securitytxt.org/.well-known/security.txt">created a basic example</a> of what could be included within the file. As you can see from the example, the location of the document differs from other plaintext examples.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>If you have advertising, check that the base directory contains a well-formed ads.txt document.</li>
									<li>Check that the base directory contains a well-formed security.txt and robots.txt document.</li>
									<li>Check that the base directory contains a well-formed carbon.txt and humans.txt document (optional).</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD20-1: Replace Deprecated Code With Suitable Alternative Syntax -->
						<details>
							<summary>WD20-1: Replace Deprecated Code With Suitable Alternative Syntax</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to identify any deprecated code that is no longer recommended for use within specifications. As older code is often not as highly optimized for performance (browser makers often cease to maintain abandoned and deprecated features), it can take longer to render and thrash hardware causing higher emissions so as a general rule, is worth resolving.</p>
								<p>For machine testability, deprecations in languages can also be found within specifications from providers like the W3C. Documentation providers like MDN also provide extremely thorough coverage of syntax that has been deprecated such as within HTML, CSS, and JavaScript. If replacements for any techniques can be offered, provide them, otherwise recommend removal from your code.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The <a href="https://www.spacejam.com/1996/">Space Jam website</a> is considered a classic piece of 90s Internet design with its total disregard for function over form, but if you look at the code - it gets even uglier with table-based layouts and deprecated code</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the project doesn't contain any outdated layout techniques (such as table-based design).</li>
									<li>Check that the website or application doesn't contain deprecated syntax features.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD20-2: Replace Outdated Web Standards With Suitable Alternatives -->
						<details>
							<summary>WD20-2: Replace Outdated Web Standards With Suitable Alternatives</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to identify technologies and web standards that may be in use but have been superseded by newer technologies and web standards. In certain cases, the standards in use may still be actively supported by web browsers and if there is a sustainability reason to retain the feature, continue. Otherwise, updating the code should be considered.</p>
								<p>As with outdated and proprietary code, web browsers tend to stop providing optimizations for outdated practices and as such, using technologies that have a newer replacement may have inherent sustainability benefits. For machine testability, standards providers list current web standards and this can be matched against in-use technologies (which often can be detected in code).</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>The <a href="https://www.webdesignmuseum.org/flash-websites">Web Design Museum</a> houses a showcase of screenshots of websites that were built using the proprietary technology Adobe Flash. Along with Java Applets and Microsoft Silverlight they now no longer work.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if the existing product or service uses outdated technologies (<abbr title="Vector Markup Language">VML</abbr> / <abbr title="Platform for Privacy Preferences">P3P</abbr>, etc) and if so recommend replacements (<abbr title="Extensible 3D">X3D</abbr> / <abbr title="Protocol for Web Description Resources">POWDER</abbr>, etc).</li>
									<li>Check for proprietary web plugins (like Flash) and remove them until a replacement can be created.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD21-1: Encourage the Use of More Sustainable Creation Toolchains -->
						<details>
							<summary>WD21-1: Encourage the Use of More Sustainable Creation Toolchains</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism of choice when creators decide how to build their product or service. This technique aims to identify how they created their product or service (if possible) and make recommendations based on the sustainability of such methods. This should take into account the creator's ability as well as the tooling dimension.</p>
								<p>For machine testability, internal access may be required if no traces of the creation tool have been left in the production code. If the production code does however contain fingerprints of the tool that created it, recommendations can be made to prioritize static over dynamic and flat-static over generated-static as reducing the processing effort on servers and client machines is meaningful.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li><a href="https://jekyllrb.com/">Jeckyll</a> is one of many solutions that exist as a solution for producing a website - in this case, it uses markdown and bundles the plaintext into a finalized pure HTML state (which should have a low carbon output).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check for the tool used for creation and determine its sustainability.</li>
									<li>If it has a low impact, continue. Otherwise, flag for replacement.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD21-4: Test All Third-Party Resources for Sustainability Impacts -->
						<details>
							<summary>WD21-4: Test All Third-Party Resources for Sustainability Impacts</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to provide a mechanism for testing third-party plugins, extensions, and themes (if such devices are used within a product or service's creation process) for any sustainability impacts they may have. These often are included within CMS software and are external assets that can add overheads to the website or application being rendered.</p>
								<p>For machine testability, many CMS products provide trace details of included features within the source code of a page (as conditional comments) due to these having to be loaded as third-party resources. Internal access may be required to get a full picture of everything being loaded. Third-party resources should be tested against the WSGs separately to identify sustainability issues.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>When using WordPress as their primary content management system, they often want to have a distinctive layout for their blog or website. As such they will install a custom theme, and its code with sustainability impacts will be imported into the total bundle size. So be careful what you choose!</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if any third-party resources exist within the page or application.</li>
									<li>Check that component against the WSGs for its sustainability compliance.</li>
									<li>Check if high-impact third-party resources offer self-hosted alternatives.</li>
									<li>Check that self-hosted alternatives are used if provided.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD22-1: Ensure the Latest Version of a Syntax Language Is Being Used -->
						<details>
							<summary>WD22-1: Ensure the Latest Version of a Syntax Language Is Being Used</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to ensure that the product or service is making use of the latest version of the chosen syntax language. As with keeping dependencies up-to-date, having the latest version of a syntax language can have sustainability benefits in terms of performance and security enhancements as well as useful, optimized new features so it's worthwhile.</p>
								<p>For machine testability, it will be difficult to verify the latest version of a syntax language is being used because, for security reasons (to avoid exploitation), most servers will not give out such information. As such, internal access will be required or a mixture of feature detection, source code examination, and the potential for asking the user of the tooling questions to establish versions.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>PHP provides a list of the <a href="https://www.php.net/supported-versions.php">supported</a> and <a href="https://www.php.net/releases/index.php">unsupported</a> versions of their programming language. You should be able to manage updates and upgrades within a hosting provider's control panel (if required).</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check that the version of a programming language being used is the latest.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
					<li> <!-- WD23-1: Replace Code That Can Instead Use More Efficient Native APIs -->
						<details>
							<summary>WD23-1: Replace Code That Can Instead Use More Efficient Native APIs</summary>
							<div class="note" title="About This Technique">
								<p><strong>Description</strong></p>
								<p>The objective of this technique is to first identify and then determine if custom JavaScript functions could be replaced with a more optimal and established native API call. This will also apply to custom element creation over using established native features to the browser. With the evolution of JavaScript, the opportunity to optimize code with newer cleaner techniques occurs regularly.</p>
								<p>It is preferable to measure both the newer method of implementation with the older method to identify if one provides a more optimized (via performance and sustainability metrics) implementation than the other before replacement. Also, this technique is most useful when considering if the custom component provides additional functionality that the native component does not and if such features weigh up beneficially against the cleaner native implementation.</p>
								<p><strong>Examples</strong></p>
								<ol>
									<li>MDN provides a <a href="https://developer.mozilla.org/en-US/docs/Web/API">great list of native Web APIs</a> for JavaScript including the interfaces that can be used to call them. Within each of those items, you will find detailed documentation along with examples of usage.</li>
								</ol>
								<p><strong>Tests</strong></p>
								<p>Procedure</p>
								<ol>
									<li>Check if the benefits of a native browser control exceed creating a custom element.</li>
									<li>Check if a native API exists that could replace custom calls, methods, or functions.</li>
									<li>In either of these instances, if the answer is yes, check that the native option is used.</li>
								</ol>
								<p>Expected Results</p>
								<ol>
									<li>All checks above are true.</li>
								</ol>
							</div>
						</details>
					</li>
				</ol>
			</section>
			<section> <!-- Hosting, Infrastructure and Systems -->
				<h3><dfn data-lt="Hosting">Hosting, Infrastructure and Systems</dfn></h3>
				<p class="ednote" title="Awaiting Content">
					This will contain testable and implementable techniques for this category.
				</p>
			</section>
			<section> <!-- Business Strategy and Product Management -->
				<h3><dfn data-lt="Business">Business Strategy and Product Management</dfn></h3>
				<p class="ednote" title="Awaiting Content">
					This will contain testable and implementable techniques for this category.
				</p>
			</section>
		</section>
		<section class="informative"> <!-- Test Suite -->
			<h2>Test Suite</h2>
			<p><a>Interoperability</a> is important to web professionals. Better interoperability among implementations means that web professionals can create websites, applications, and tooling designed to be sustainable, and ensure that it is successfully repeatable (and testable) in several environments. It means reducing the potential for Web sustainability issues to occur in complex projects and reducing the implementation time where automation and tooling can assist during the creation, development, and maintenance process. Writing tests in a way that allows them to be run in all browsers gives implementors confidence that they are shipping software that will be compatible, and consistent with other implementations.</p>
			<p>Good test suites drive interoperability. They are a key part of making sure web standards are implemented correctly and consistently. More tests encourage more interoperability. Wrong tests drive interoperability on wrong behavior. As such, Web Sustainability needs good test suites. It's an evolving field and most of the test suites are still works in progress: so they may contain errors.</p>
			<p>The primary focus of this test suite is to provide interoperability for tool makers (in terms of automation and compliance with the WSGs). In addition, we also aim to provide meaningful testable metrics that can be measured and help identify the true impact of the Success Criteria within the WSGs, and therefore better understand the impact that digital has on the ecosystem.</p>
			<p>Implementors could use the dataset provided to expand upon the results and offer more nuanced research. Additionally, there is the potential for toolmakers to create more accurate products that measure the carbon impact of products. While the scope of such matters may potentially stretch beyond this group's remit, the results could feed back into - and impact further iterations of our work.</p>
			<section> <!-- Table of Results -->
				<h3>Table of Results</h3>
				<p class="ednote" title="Awaiting Content">
					This will contain a link to our GitHub test suite folder and individual tests.
				</p>
				<p>The below table contains links to our test suite results generated using a cross-section of machine-readable techniques from the previous section.</p>
				<ul>
					<li><strong>N/A</strong> is an indication that results are not available.</li>
					<li><strong>PASS</strong> is an indication that the test was able to be performed successfully.</li>
					<li><strong>FAIL</strong> is an indication that the test was unable to be performed and no test was subsequently produced.</li>
				</ul>
				<p>The tests themselves (along with any corresponding reports generated) are stored on GitHub in our public repository under the <a href="https://github.com/w3c/sustyweb/tree/main/test-suite/">test-suite</a> folder.</p>
				<div class="flow">
					<table>
						<thead>
						<tr>
							<th colspan="2"></th>
							<th colspan="5"><a>UX</a></th>
							<th colspan="6"><a>WebDev</a></th>
							<th colspan="6"><a>Hosting</a></th>
							<th colspan="6"><a>Business</a></th>
						</tr>
						</thead>
						<tbody>
							<tr>
								<td><strong>Guideline</strong></td>
								<td><strong><abbr title="Success Criteria">SC</abbr></strong></td>
								<td>1</td>
								<td>2</td>
								<td>3</td>
								<td>4</td>
								<td>5</td>
								<td>1</td>
								<td>2</td>
								<td>3</td>
								<td>4</td>
								<td>5</td>
								<td>6</td>
								<td>1</td>
								<td>2</td>
								<td>3</td>
								<td>4</td>
								<td>5</td>
								<td>6</td>
								<td>1</td>
								<td>2</td>
								<td>3</td>
								<td>4</td>
								<td>5</td>
								<td>6</td>
							</tr>
							<tr>
								<td colspan="2">1</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
							</tr>
							<tr>
								<td colspan="2">2</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>

								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">3</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">4</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">5</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>

								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">6</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>

								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>

								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">7</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>

								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">8</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>

								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">9</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">10</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">11</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>

								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">12</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>

								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
							</tr>
							<tr>
								<td colspan="2">13</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">14</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">15</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>

								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">16</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>

								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">17</td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">18</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">19</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>

								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">20</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">21</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">22</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">23</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>

								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">24</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td></td>

								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">25</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">26</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">27</td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">28</td>
								<td class="red">FAIL</td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td colspan="2">29</td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td><a href="">N/A</a></td>
								<td class="red">FAIL</td>
								<td><a href="">N/A</a></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>

								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
								<td></td>
							</tr>
						</tbody>
					</table>
				</div>
				<p>If attempting to create a test to include within or expand the test suite, remember to follow these <a href="https://web-platform-tests.org/reviewing-tests/checklist.html">review guidelines</a>. Also, be sure to remember that qualitative as well as quantitative tests are equally valuable as long as they can be tested by machine (and thus automated in some way). As tests will provide a means of identifying whether Success Criteria can offer Automated testing over Manual interventions, notifications of this potential attribute (and methods) will be referenced within the main specification.</p>
			</section>
		</section>
		<section class="informative"> <!-- Glossary -->
			<h2>Glossary</h2>
			<dl id="terms">
				<dt><dfn>Interoperability</dfn></dt>
				<dd>
					<p>Interoperability is the ability of two or more systems or components to exchange information and to use the information that has been exchanged.</p>
				</dd>
			</dl>
		</section>
	</body>
</html>